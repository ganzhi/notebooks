{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ef4f340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "067da5df-e339-4da4-b4ea-6ae67e8c329c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 9912422/9912422 [00:00<00:00, 11179614.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 28881/28881 [00:00<00:00, 38177022.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 1648877/1648877 [00:00<00:00, 8415510.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 4542/4542 [00:00<00:00, 7108406.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff967ca2-c514-43f4-9f71-cf00b3063ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1),  # Input: 28x28\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1), # Output: 7x7\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),     # Flatten into a vector\n",
    "            nn.Linear(32 * 7 * 7, 128), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(128, 32 * 7 * 7),              \n",
    "            nn.ReLU(),           \n",
    "            nn.Unflatten(1, (32, 7, 7)),            # Reshape\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),  \n",
    "            nn.Tanh()  # Use Tanh to keep output between -1 and 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e22d170a-1846-4e59-bfdf-1e1bab7f3cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Conv2d in module torch.nn.modules.conv:\n",
      "\n",
      "class Conv2d(_ConvNd)\n",
      " |  Conv2d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int, int]], stride: Union[int, Tuple[int, int]] = 1, padding: Union[str, int, Tuple[int, int]] = 0, dilation: Union[int, Tuple[int, int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None) -> None\n",
      " |  \n",
      " |  Applies a 2D convolution over an input signal composed of several input\n",
      " |  planes.\n",
      " |  \n",
      " |  In the simplest case, the output value of the layer with input size\n",
      " |  :math:`(N, C_{\\text{in}}, H, W)` and output :math:`(N, C_{\\text{out}}, H_{\\text{out}}, W_{\\text{out}})`\n",
      " |  can be precisely described as:\n",
      " |  \n",
      " |  .. math::\n",
      " |      \\text{out}(N_i, C_{\\text{out}_j}) = \\text{bias}(C_{\\text{out}_j}) +\n",
      " |      \\sum_{k = 0}^{C_{\\text{in}} - 1} \\text{weight}(C_{\\text{out}_j}, k) \\star \\text{input}(N_i, k)\n",
      " |  \n",
      " |  \n",
      " |  where :math:`\\star` is the valid 2D `cross-correlation`_ operator,\n",
      " |  :math:`N` is a batch size, :math:`C` denotes a number of channels,\n",
      " |  :math:`H` is a height of input planes in pixels, and :math:`W` is\n",
      " |  width in pixels.\n",
      " |  \n",
      " |  \n",
      " |  This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
      " |  \n",
      " |  On certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n",
      " |  \n",
      " |  * :attr:`stride` controls the stride for the cross-correlation, a single\n",
      " |    number or a tuple.\n",
      " |  \n",
      " |  * :attr:`padding` controls the amount of padding applied to the input. It\n",
      " |    can be either a string {'valid', 'same'} or an int / a tuple of ints giving the\n",
      " |    amount of implicit padding applied on both sides.\n",
      " |  \n",
      " |  * :attr:`dilation` controls the spacing between the kernel points; also\n",
      " |    known as the à trous algorithm. It is harder to describe, but this `link`_\n",
      " |    has a nice visualization of what :attr:`dilation` does.\n",
      " |  \n",
      " |  * :attr:`groups` controls the connections between inputs and outputs.\n",
      " |    :attr:`in_channels` and :attr:`out_channels` must both be divisible by\n",
      " |    :attr:`groups`. For example,\n",
      " |  \n",
      " |      * At groups=1, all inputs are convolved to all outputs.\n",
      " |      * At groups=2, the operation becomes equivalent to having two conv\n",
      " |        layers side by side, each seeing half the input channels\n",
      " |        and producing half the output channels, and both subsequently\n",
      " |        concatenated.\n",
      " |      * At groups= :attr:`in_channels`, each input channel is convolved with\n",
      " |        its own set of filters (of size\n",
      " |        :math:`\\frac{\\text{out\\_channels}}{\\text{in\\_channels}}`).\n",
      " |  \n",
      " |  The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`dilation` can either be:\n",
      " |  \n",
      " |      - a single ``int`` -- in which case the same value is used for the height and width dimension\n",
      " |      - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,\n",
      " |        and the second `int` for the width dimension\n",
      " |  \n",
      " |  Note:\n",
      " |      When `groups == in_channels` and `out_channels == K * in_channels`,\n",
      " |      where `K` is a positive integer, this operation is also known as a \"depthwise convolution\".\n",
      " |  \n",
      " |      In other words, for an input of size :math:`(N, C_{in}, L_{in})`,\n",
      " |      a depthwise convolution with a depthwise multiplier `K` can be performed with the arguments\n",
      " |      :math:`(C_\\text{in}=C_\\text{in}, C_\\text{out}=C_\\text{in} \\times \\text{K}, ..., \\text{groups}=C_\\text{in})`.\n",
      " |  \n",
      " |  Note:\n",
      " |      In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting ``torch.backends.cudnn.deterministic = True``. See :doc:`/notes/randomness` for more information.\n",
      " |  \n",
      " |  Note:\n",
      " |      ``padding='valid'`` is the same as no padding. ``padding='same'`` pads\n",
      " |      the input so the output has the shape as the input. However, this mode\n",
      " |      doesn't support any stride values other than 1.\n",
      " |  \n",
      " |  Note:\n",
      " |      This module supports complex data types i.e. ``complex32, complex64, complex128``.\n",
      " |  \n",
      " |  Args:\n",
      " |      in_channels (int): Number of channels in the input image\n",
      " |      out_channels (int): Number of channels produced by the convolution\n",
      " |      kernel_size (int or tuple): Size of the convolving kernel\n",
      " |      stride (int or tuple, optional): Stride of the convolution. Default: 1\n",
      " |      padding (int, tuple or str, optional): Padding added to all four sides of\n",
      " |          the input. Default: 0\n",
      " |      padding_mode (str, optional): ``'zeros'``, ``'reflect'``,\n",
      " |          ``'replicate'`` or ``'circular'``. Default: ``'zeros'``\n",
      " |      dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n",
      " |      groups (int, optional): Number of blocked connections from input\n",
      " |          channels to output channels. Default: 1\n",
      " |      bias (bool, optional): If ``True``, adds a learnable bias to the\n",
      " |          output. Default: ``True``\n",
      " |  \n",
      " |  \n",
      " |  Shape:\n",
      " |      - Input: :math:`(N, C_{in}, H_{in}, W_{in})` or :math:`(C_{in}, H_{in}, W_{in})`\n",
      " |      - Output: :math:`(N, C_{out}, H_{out}, W_{out})` or :math:`(C_{out}, H_{out}, W_{out})`, where\n",
      " |  \n",
      " |        .. math::\n",
      " |            H_{out} = \\left\\lfloor\\frac{H_{in}  + 2 \\times \\text{padding}[0] - \\text{dilation}[0]\n",
      " |                      \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\n",
      " |  \n",
      " |        .. math::\n",
      " |            W_{out} = \\left\\lfloor\\frac{W_{in}  + 2 \\times \\text{padding}[1] - \\text{dilation}[1]\n",
      " |                      \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\n",
      " |  \n",
      " |  Attributes:\n",
      " |      weight (Tensor): the learnable weights of the module of shape\n",
      " |          :math:`(\\text{out\\_channels}, \\frac{\\text{in\\_channels}}{\\text{groups}},`\n",
      " |          :math:`\\text{kernel\\_size[0]}, \\text{kernel\\_size[1]})`.\n",
      " |          The values of these weights are sampled from\n",
      " |          :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
      " |          :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n",
      " |      bias (Tensor):   the learnable bias of the module of shape\n",
      " |          (out_channels). If :attr:`bias` is ``True``,\n",
      " |          then the values of these weights are\n",
      " |          sampled from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
      " |          :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n",
      " |  \n",
      " |  Examples:\n",
      " |  \n",
      " |      >>> # With square kernels and equal stride\n",
      " |      >>> m = nn.Conv2d(16, 33, 3, stride=2)\n",
      " |      >>> # non-square kernels and unequal stride and with padding\n",
      " |      >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n",
      " |      >>> # non-square kernels and unequal stride and with padding and dilation\n",
      " |      >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n",
      " |      >>> input = torch.randn(20, 16, 50, 100)\n",
      " |      >>> output = m(input)\n",
      " |  \n",
      " |  .. _cross-correlation:\n",
      " |      https://en.wikipedia.org/wiki/Cross-correlation\n",
      " |  \n",
      " |  .. _link:\n",
      " |      https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Conv2d\n",
      " |      _ConvNd\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int, int]], stride: Union[int, Tuple[int, int]] = 1, padding: Union[str, int, Tuple[int, int]] = 0, dilation: Union[int, Tuple[int, int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None) -> None\n",
      " |      Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
      " |  \n",
      " |  forward(self, input: torch.Tensor) -> torch.Tensor\n",
      " |      Defines the computation performed at every call.\n",
      " |      \n",
      " |      Should be overridden by all subclasses.\n",
      " |      \n",
      " |      .. note::\n",
      " |          Although the recipe for forward pass needs to be defined within\n",
      " |          this function, one should call the :class:`Module` instance afterwards\n",
      " |          instead of this since the former takes care of running the\n",
      " |          registered hooks while the latter silently ignores them.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _ConvNd:\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  extra_repr(self)\n",
      " |      Set the extra representation of the module\n",
      " |      \n",
      " |      To print customized extra information, you should re-implement\n",
      " |      this method in your own modules. Both single-line and multi-line\n",
      " |      strings are acceptable.\n",
      " |  \n",
      " |  reset_parameters(self) -> None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from _ConvNd:\n",
      " |  \n",
      " |  __annotations__ = {'_reversed_padding_repeated_twice': typing.List[int...\n",
      " |  \n",
      " |  __constants__ = ['stride', 'padding', 'dilation', 'groups', 'padding_m...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__ = _call_impl(self, *args, **kwargs)\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Default dir() implementation.\n",
      " |  \n",
      " |  __getattr__(self, name: str) -> Union[torch.Tensor, ForwardRef('Module')]\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name: str, value: Union[torch.Tensor, ForwardRef('Module')]) -> None\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  add_module(self, name: str, module: Optional[ForwardRef('Module')]) -> None\n",
      " |      Adds a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          module (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self: ~T, fn: Callable[[ForwardRef('Module')], NoneType]) -> ~T\n",
      " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
      " |      as well as self. Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`nn-init-doc`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> @torch.no_grad()\n",
      " |          >>> def init_weights(m):\n",
      " |          >>>     print(m)\n",
      " |          >>>     if type(m) == nn.Linear:\n",
      " |          >>>         m.weight.fill_(1.0)\n",
      " |          >>>         print(m.weight)\n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[1., 1.],\n",
      " |                  [1., 1.]], requires_grad=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[1., 1.],\n",
      " |                  [1., 1.]], requires_grad=True)\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |  \n",
      " |  bfloat16(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``bfloat16`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  buffers(self, recurse: bool = True) -> Iterator[torch.Tensor]\n",
      " |      Returns an iterator over module buffers.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          torch.Tensor: module buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for buf in model.buffers():\n",
      " |          >>>     print(type(buf), buf.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  children(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  cpu(self: ~T) -> ~T\n",
      " |      Moves all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self: ~T) -> ~T\n",
      " |      Sets the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
      " |      \n",
      " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
      " |      `.eval()` and several similar mechanisms that may be confused with it.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  float(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``float`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  get_buffer(self, target: str) -> 'Tensor'\n",
      " |      Returns the buffer given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      See the docstring for ``get_submodule`` for a more detailed\n",
      " |      explanation of this method's functionality as well as how to\n",
      " |      correctly specify ``target``.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the buffer\n",
      " |              to look for. (See ``get_submodule`` for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.Tensor: The buffer referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not a\n",
      " |              buffer\n",
      " |  \n",
      " |  get_extra_state(self) -> Any\n",
      " |      Returns any extra state to include in the module's state_dict.\n",
      " |      Implement this and a corresponding :func:`set_extra_state` for your module\n",
      " |      if you need to store extra state. This function is called when building the\n",
      " |      module's `state_dict()`.\n",
      " |      \n",
      " |      Note that extra state should be picklable to ensure working serialization\n",
      " |      of the state_dict. We only provide provide backwards compatibility guarantees\n",
      " |      for serializing Tensors; other objects may break backwards compatibility if\n",
      " |      their serialized pickled form changes.\n",
      " |      \n",
      " |      Returns:\n",
      " |          object: Any extra state to store in the module's state_dict\n",
      " |  \n",
      " |  get_parameter(self, target: str) -> 'Parameter'\n",
      " |      Returns the parameter given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      See the docstring for ``get_submodule`` for a more detailed\n",
      " |      explanation of this method's functionality as well as how to\n",
      " |      correctly specify ``target``.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the Parameter\n",
      " |              to look for. (See ``get_submodule`` for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.nn.Parameter: The Parameter referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not an\n",
      " |              ``nn.Parameter``\n",
      " |  \n",
      " |  get_submodule(self, target: str) -> 'Module'\n",
      " |      Returns the submodule given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      For example, let's say you have an ``nn.Module`` ``A`` that\n",
      " |      looks like this:\n",
      " |      \n",
      " |      .. code-block:: text\n",
      " |      \n",
      " |          A(\n",
      " |              (net_b): Module(\n",
      " |                  (net_c): Module(\n",
      " |                      (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))\n",
      " |                  )\n",
      " |                  (linear): Linear(in_features=100, out_features=200, bias=True)\n",
      " |              )\n",
      " |          )\n",
      " |      \n",
      " |      (The diagram shows an ``nn.Module`` ``A``. ``A`` has a nested\n",
      " |      submodule ``net_b``, which itself has two submodules ``net_c``\n",
      " |      and ``linear``. ``net_c`` then has a submodule ``conv``.)\n",
      " |      \n",
      " |      To check whether or not we have the ``linear`` submodule, we\n",
      " |      would call ``get_submodule(\"net_b.linear\")``. To check whether\n",
      " |      we have the ``conv`` submodule, we would call\n",
      " |      ``get_submodule(\"net_b.net_c.conv\")``.\n",
      " |      \n",
      " |      The runtime of ``get_submodule`` is bounded by the degree\n",
      " |      of module nesting in ``target``. A query against\n",
      " |      ``named_modules`` achieves the same result, but it is O(N) in\n",
      " |      the number of transitive modules. So, for a simple check to see\n",
      " |      if some submodule exists, ``get_submodule`` should always be\n",
      " |      used.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the submodule\n",
      " |              to look for. (See above example for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.nn.Module: The submodule referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not an\n",
      " |              ``nn.Module``\n",
      " |  \n",
      " |  half(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  ipu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the IPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on IPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict: Mapping[str, Any], strict: bool = True)\n",
      " |      Copies parameters and buffers from :attr:`state_dict` into\n",
      " |      this module and its descendants. If :attr:`strict` is ``True``, then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      " |      \n",
      " |      Args:\n",
      " |          state_dict (dict): a dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool, optional): whether to strictly enforce that the keys\n",
      " |              in :attr:`state_dict` match the keys returned by this module's\n",
      " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      " |      \n",
      " |      Returns:\n",
      " |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
      " |              * **missing_keys** is a list of str containing the missing keys\n",
      " |              * **unexpected_keys** is a list of str containing the unexpected keys\n",
      " |      \n",
      " |      Note:\n",
      " |          If a parameter or buffer is registered as ``None`` and its corresponding key\n",
      " |          exists in :attr:`state_dict`, :meth:`load_state_dict` will raise a\n",
      " |          ``RuntimeError``.\n",
      " |  \n",
      " |  modules(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |          ...     print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          1 -> Linear(in_features=2, out_features=2, bias=True)\n",
      " |  \n",
      " |  named_buffers(self, prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n",
      " |      Returns an iterator over module buffers, yielding both the\n",
      " |      name of the buffer as well as the buffer itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all buffer names.\n",
      " |          recurse (bool, optional): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module. Defaults to True.\n",
      " |          remove_duplicate (bool, optional): whether to remove the duplicated buffers in the result. Defaults to True.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, torch.Tensor): Tuple containing the name and buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, buf in self.named_buffers():\n",
      " |          >>>     if name in ['running_var']:\n",
      " |          >>>         print(buf.size())\n",
      " |  \n",
      " |  named_children(self) -> Iterator[Tuple[str, ForwardRef('Module')]]\n",
      " |      Returns an iterator over immediate children modules, yielding both\n",
      " |      the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo: Optional[Set[ForwardRef('Module')]] = None, prefix: str = '', remove_duplicate: bool = True)\n",
      " |      Returns an iterator over all modules in the network, yielding\n",
      " |      both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          memo: a memo to store the set of modules already added to the result\n",
      " |          prefix: a prefix that will be added to the name of the module\n",
      " |          remove_duplicate: whether to remove the duplicated module instances in the result\n",
      " |              or not\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |          ...     print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> ('', Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
      " |  \n",
      " |  named_parameters(self, prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) -> Iterator[Tuple[str, torch.nn.parameter.Parameter]]\n",
      " |      Returns an iterator over module parameters, yielding both the\n",
      " |      name of the parameter as well as the parameter itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all parameter names.\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |          remove_duplicate (bool, optional): whether to remove the duplicated\n",
      " |              parameters in the result. Defaults to True.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>     if name in ['bias']:\n",
      " |          >>>         print(param.size())\n",
      " |  \n",
      " |  parameters(self, recurse: bool = True) -> Iterator[torch.nn.parameter.Parameter]\n",
      " |      Returns an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param), param.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, Tuple[torch.Tensor, ...], torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      This function is deprecated in favor of :meth:`~torch.nn.Module.register_full_backward_hook` and\n",
      " |      the behavior of this function will change in future versions.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_buffer(self, name: str, tensor: Optional[torch.Tensor], persistent: bool = True) -> None\n",
      " |      Adds a buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the module's state. Buffers, by\n",
      " |      default, are persistent and will be saved alongside parameters. This\n",
      " |      behavior can be changed by setting :attr:`persistent` to ``False``. The\n",
      " |      only difference between a persistent buffer and a non-persistent buffer\n",
      " |      is that the latter will not be a part of this module's\n",
      " |      :attr:`state_dict`.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor or None): buffer to be registered. If ``None``, then operations\n",
      " |              that run on buffers, such as :attr:`cuda`, are ignored. If ``None``,\n",
      " |              the buffer is **not** included in the module's :attr:`state_dict`.\n",
      " |          persistent (bool): whether the buffer is part of this module's\n",
      " |              :attr:`state_dict`.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook: Union[Callable[[~T, Tuple[Any, ...], Any], Optional[Any]], Callable[[~T, Tuple[Any, ...], Dict[str, Any], Any], Optional[Any]]], *, prepend: bool = False, with_kwargs: bool = False) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      \n",
      " |      If ``with_kwargs`` is ``False`` or not specified, the input contains only\n",
      " |      the positional arguments given to the module. Keyword arguments won't be\n",
      " |      passed to the hooks and only to the ``forward``. The hook can modify the\n",
      " |      output. It can modify the input inplace but it will not have effect on\n",
      " |      forward since this is called after :func:`forward` is called. The hook\n",
      " |      should have the following signature::\n",
      " |      \n",
      " |          hook(module, args, output) -> None or modified output\n",
      " |      \n",
      " |      If ``with_kwargs`` is ``True``, the forward hook will be passed the\n",
      " |      ``kwargs`` given to the forward function and be expected to return the\n",
      " |      output possibly modified. The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, args, kwargs, output) -> None or modified output\n",
      " |      \n",
      " |      Args:\n",
      " |          hook (Callable): The user defined hook to be registered.\n",
      " |          prepend (bool): If ``True``, the provided ``hook`` will be fired\n",
      " |              before all existing ``forward`` hooks on this\n",
      " |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n",
      " |              ``hook`` will be fired after all existing ``forward`` hooks on\n",
      " |              this :class:`torch.nn.modules.Module`. Note that global\n",
      " |              ``forward`` hooks registered with\n",
      " |              :func:`register_module_forward_hook` will fire before all hooks\n",
      " |              registered by this method.\n",
      " |              Default: ``False``\n",
      " |          with_kwargs (bool): If ``True``, the ``hook`` will be passed the\n",
      " |              kwargs given to the forward function.\n",
      " |              Default: ``False``\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook: Union[Callable[[~T, Tuple[Any, ...]], Optional[Any]], Callable[[~T, Tuple[Any, ...], Dict[str, Any]], Optional[Tuple[Any, Dict[str, Any]]]]], *, prepend: bool = False, with_kwargs: bool = False) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      \n",
      " |      \n",
      " |      If ``with_kwargs`` is false or not specified, the input contains only\n",
      " |      the positional arguments given to the module. Keyword arguments won't be\n",
      " |      passed to the hooks and only to the ``forward``. The hook can modify the\n",
      " |      input. User can either return a tuple or a single modified value in the\n",
      " |      hook. We will wrap the value into a tuple if a single value is returned\n",
      " |      (unless that value is already a tuple). The hook should have the\n",
      " |      following signature::\n",
      " |      \n",
      " |          hook(module, args) -> None or modified input\n",
      " |      \n",
      " |      If ``with_kwargs`` is true, the forward pre-hook will be passed the\n",
      " |      kwargs given to the forward function. And if the hook modifies the\n",
      " |      input, both the args and kwargs should be returned. The hook should have\n",
      " |      the following signature::\n",
      " |      \n",
      " |          hook(module, args, kwargs) -> None or a tuple of modified input and kwargs\n",
      " |      \n",
      " |      Args:\n",
      " |          hook (Callable): The user defined hook to be registered.\n",
      " |          prepend (bool): If true, the provided ``hook`` will be fired before\n",
      " |              all existing ``forward_pre`` hooks on this\n",
      " |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n",
      " |              ``hook`` will be fired after all existing ``forward_pre`` hooks\n",
      " |              on this :class:`torch.nn.modules.Module`. Note that global\n",
      " |              ``forward_pre`` hooks registered with\n",
      " |              :func:`register_module_forward_pre_hook` will fire before all\n",
      " |              hooks registered by this method.\n",
      " |              Default: ``False``\n",
      " |          with_kwargs (bool): If true, the ``hook`` will be passed the kwargs\n",
      " |              given to the forward function.\n",
      " |              Default: ``False``\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_full_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, Tuple[torch.Tensor, ...], torch.Tensor]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to a module\n",
      " |      are computed, i.e. the hook will execute if and only if the gradients with\n",
      " |      respect to module outputs are computed. The hook should have the following\n",
      " |      signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> tuple(Tensor) or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` are tuples that contain the gradients\n",
      " |      with respect to the inputs and outputs respectively. The hook should\n",
      " |      not modify its arguments, but it can optionally return a new gradient with\n",
      " |      respect to the input that will be used in place of :attr:`grad_input` in\n",
      " |      subsequent computations. :attr:`grad_input` will only correspond to the inputs given\n",
      " |      as positional arguments and all kwarg arguments are ignored. Entries\n",
      " |      in :attr:`grad_input` and :attr:`grad_output` will be ``None`` for all non-Tensor\n",
      " |      arguments.\n",
      " |      \n",
      " |      For technical reasons, when this hook is applied to a Module, its forward function will\n",
      " |      receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\n",
      " |      of each Tensor returned by the Module's forward function.\n",
      " |      \n",
      " |      .. warning ::\n",
      " |          Modifying inputs or outputs inplace is not allowed when using backward hooks and\n",
      " |          will raise an error.\n",
      " |      \n",
      " |      Args:\n",
      " |          hook (Callable): The user-defined hook to be registered.\n",
      " |          prepend (bool): If true, the provided ``hook`` will be fired before\n",
      " |              all existing ``backward`` hooks on this\n",
      " |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n",
      " |              ``hook`` will be fired after all existing ``backward`` hooks on\n",
      " |              this :class:`torch.nn.modules.Module`. Note that global\n",
      " |              ``backward`` hooks registered with\n",
      " |              :func:`register_module_full_backward_hook` will fire before\n",
      " |              all hooks registered by this method.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_full_backward_pre_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, Tuple[torch.Tensor, ...], torch.Tensor]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients for the module are computed.\n",
      " |      The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, grad_output) -> Tensor or None\n",
      " |      \n",
      " |      The :attr:`grad_output` is a tuple. The hook should\n",
      " |      not modify its arguments, but it can optionally return a new gradient with\n",
      " |      respect to the output that will be used in place of :attr:`grad_output` in\n",
      " |      subsequent computations. Entries in :attr:`grad_output` will be ``None`` for\n",
      " |      all non-Tensor arguments.\n",
      " |      \n",
      " |      For technical reasons, when this hook is applied to a Module, its forward function will\n",
      " |      receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\n",
      " |      of each Tensor returned by the Module's forward function.\n",
      " |      \n",
      " |      .. warning ::\n",
      " |          Modifying inputs inplace is not allowed when using backward hooks and\n",
      " |          will raise an error.\n",
      " |      \n",
      " |      Args:\n",
      " |          hook (Callable): The user-defined hook to be registered.\n",
      " |          prepend (bool): If true, the provided ``hook`` will be fired before\n",
      " |              all existing ``backward_pre`` hooks on this\n",
      " |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n",
      " |              ``hook`` will be fired after all existing ``backward_pre`` hooks\n",
      " |              on this :class:`torch.nn.modules.Module`. Note that global\n",
      " |              ``backward_pre`` hooks registered with\n",
      " |              :func:`register_module_full_backward_pre_hook` will fire before\n",
      " |              all hooks registered by this method.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_load_state_dict_post_hook(self, hook)\n",
      " |      Registers a post hook to be run after module's ``load_state_dict``\n",
      " |      is called.\n",
      " |      \n",
      " |      It should have the following signature::\n",
      " |          hook(module, incompatible_keys) -> None\n",
      " |      \n",
      " |      The ``module`` argument is the current module that this hook is registered\n",
      " |      on, and the ``incompatible_keys`` argument is a ``NamedTuple`` consisting\n",
      " |      of attributes ``missing_keys`` and ``unexpected_keys``. ``missing_keys``\n",
      " |      is a ``list`` of ``str`` containing the missing keys and\n",
      " |      ``unexpected_keys`` is a ``list`` of ``str`` containing the unexpected keys.\n",
      " |      \n",
      " |      The given incompatible_keys can be modified inplace if needed.\n",
      " |      \n",
      " |      Note that the checks performed when calling :func:`load_state_dict` with\n",
      " |      ``strict=True`` are affected by modifications the hook makes to\n",
      " |      ``missing_keys`` or ``unexpected_keys``, as expected. Additions to either\n",
      " |      set of keys will result in an error being thrown when ``strict=True``, and\n",
      " |      clearing out both missing and unexpected keys will avoid an error.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_module(self, name: str, module: Optional[ForwardRef('Module')]) -> None\n",
      " |      Alias for :func:`add_module`.\n",
      " |  \n",
      " |  register_parameter(self, name: str, param: Optional[torch.nn.parameter.Parameter]) -> None\n",
      " |      Adds a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          param (Parameter or None): parameter to be added to the module. If\n",
      " |              ``None``, then operations that run on parameters, such as :attr:`cuda`,\n",
      " |              are ignored. If ``None``, the parameter is **not** included in the\n",
      " |              module's :attr:`state_dict`.\n",
      " |  \n",
      " |  register_state_dict_pre_hook(self, hook)\n",
      " |      These hooks will be called with arguments: ``self``, ``prefix``,\n",
      " |      and ``keep_vars`` before calling ``state_dict`` on ``self``. The registered\n",
      " |      hooks can be used to perform pre-processing before the ``state_dict``\n",
      " |      call is made.\n",
      " |  \n",
      " |  requires_grad_(self: ~T, requires_grad: bool = True) -> ~T\n",
      " |      Change if autograd should record operations on parameters in this\n",
      " |      module.\n",
      " |      \n",
      " |      This method sets the parameters' :attr:`requires_grad` attributes\n",
      " |      in-place.\n",
      " |      \n",
      " |      This method is helpful for freezing part of the module for finetuning\n",
      " |      or training parts of a model individually (e.g., GAN training).\n",
      " |      \n",
      " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
      " |      `.requires_grad_()` and several similar mechanisms that may be confused with it.\n",
      " |      \n",
      " |      Args:\n",
      " |          requires_grad (bool): whether autograd should record operations on\n",
      " |                                parameters in this module. Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  set_extra_state(self, state: Any)\n",
      " |      This function is called from :func:`load_state_dict` to handle any extra state\n",
      " |      found within the `state_dict`. Implement this function and a corresponding\n",
      " |      :func:`get_extra_state` for your module if you need to store extra state within its\n",
      " |      `state_dict`.\n",
      " |      \n",
      " |      Args:\n",
      " |          state (dict): Extra state from the `state_dict`\n",
      " |  \n",
      " |  share_memory(self: ~T) -> ~T\n",
      " |      See :meth:`torch.Tensor.share_memory_`\n",
      " |  \n",
      " |  state_dict(self, *args, destination=None, prefix='', keep_vars=False)\n",
      " |      Returns a dictionary containing references to the whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      Parameters and buffers set to ``None`` are not included.\n",
      " |      \n",
      " |      .. note::\n",
      " |          The returned object is a shallow copy. It contains references\n",
      " |          to the module's parameters and buffers.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          Currently ``state_dict()`` also accepts positional arguments for\n",
      " |          ``destination``, ``prefix`` and ``keep_vars`` in order. However,\n",
      " |          this is being deprecated and keyword arguments will be enforced in\n",
      " |          future releases.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          Please avoid the use of argument ``destination`` as it is not\n",
      " |          designed for end-users.\n",
      " |      \n",
      " |      Args:\n",
      " |          destination (dict, optional): If provided, the state of module will\n",
      " |              be updated into the dict and the same object is returned.\n",
      " |              Otherwise, an ``OrderedDict`` will be created and returned.\n",
      " |              Default: ``None``.\n",
      " |          prefix (str, optional): a prefix added to parameter and buffer\n",
      " |              names to compose the keys in state_dict. Default: ``''``.\n",
      " |          keep_vars (bool, optional): by default the :class:`~torch.Tensor` s\n",
      " |              returned in the state dict are detached from autograd. If it's\n",
      " |              set to ``True``, detaching will not be performed.\n",
      " |              Default: ``False``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  to(self, *args, **kwargs)\n",
      " |      Moves and/or casts the parameters and buffers.\n",
      " |      \n",
      " |      This can be called as\n",
      " |      \n",
      " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(dtype, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(tensor, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(memory_format=torch.channels_last)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
      " |      floating point or complex :attr:`dtype`\\ s. In addition, this method will\n",
      " |      only cast the floating point or complex parameters and buffers to :attr:`dtype`\n",
      " |      (if given). The integral parameters and buffers will be moved\n",
      " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
      " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
      " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
      " |      pinned memory to CUDA devices.\n",
      " |      \n",
      " |      See below for examples.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): the desired device of the parameters\n",
      " |              and buffers in this module\n",
      " |          dtype (:class:`torch.dtype`): the desired floating point or complex dtype of\n",
      " |              the parameters and buffers in this module\n",
      " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
      " |              dtype and device for all parameters and buffers in this module\n",
      " |          memory_format (:class:`torch.memory_format`): the desired memory\n",
      " |              format for 4D parameters and buffers in this module (keyword\n",
      " |              only argument)\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n",
      " |          >>> linear = nn.Linear(2, 2)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]])\n",
      " |          >>> linear.to(torch.double)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
      " |          >>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_CUDA1)\n",
      " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
      " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      " |          >>> cpu = torch.device(\"cpu\")\n",
      " |          >>> linear.to(cpu)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2, bias=None).to(torch.cdouble)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.3741+0.j,  0.2382+0.j],\n",
      " |                  [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)\n",
      " |          >>> linear(torch.ones(3, 2, dtype=torch.cdouble))\n",
      " |          tensor([[0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)\n",
      " |  \n",
      " |  to_empty(self: ~T, *, device: Union[str, torch.device]) -> ~T\n",
      " |      Moves the parameters and buffers to the specified device without copying storage.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): The desired device of the parameters\n",
      " |              and buffers in this module.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  train(self: ~T, mode: bool = True) -> ~T\n",
      " |      Sets the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      Args:\n",
      " |          mode (bool): whether to set training mode (``True``) or evaluation\n",
      " |                       mode (``False``). Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self: ~T, dst_type: Union[torch.dtype, str]) -> ~T\n",
      " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  xpu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the XPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on XPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self, set_to_none: bool = True) -> None\n",
      " |      Sets gradients of all model parameters to zero. See similar function\n",
      " |      under :class:`torch.optim.Optimizer` for more context.\n",
      " |      \n",
      " |      Args:\n",
      " |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
      " |              See :meth:`torch.optim.Optimizer.zero_grad` for details.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  T_destination = ~T_destination\n",
      " |  \n",
      " |  call_super_init = False\n",
      " |  \n",
      " |  dump_patches = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nn.Conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd35e013-0def-4a72-9e27-021afb9504f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Autoencoder().to(device)\n",
    "criterion = nn.MSELoss()  # Mean squared error loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):  # Adjust the number of epochs\n",
    "    for images, _ in train_loader:\n",
    "        images = images.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82e9a5e9-594c-414b-9e47-a9d8fee7506e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ... (after training) ...\n",
    "with torch.no_grad():\n",
    "    sample_images, _ = next(iter(test_loader))\n",
    "    output = model(sample_images.to(device))\n",
    "    # Plot original and reconstructed images side-by-side\n",
    "    # Select some images to visualize (adjust the number if needed)\n",
    "    images_to_show = 5 \n",
    "\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=images_to_show, figsize=(15, 6))\n",
    "\n",
    "    # Plot original images\n",
    "    for i in range(images_to_show):\n",
    "        axes[0, i].imshow(sample_images[i].cpu().squeeze().numpy(), cmap='gray')\n",
    "        axes[0, i].set_title('Original')\n",
    "\n",
    "    # Plot reconstructed images\n",
    "    for i in range(images_to_show):\n",
    "        axes[1, i].imshow(output[i].cpu().squeeze().numpy(), cmap='gray')\n",
    "        axes[1, i].set_title('Reconstructed')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d38ba92-b9da-41f0-a8ae-d5e735aabe47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 tensor(0.1397, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch:  1 tensor(0.0941, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch:  2 tensor(0.0643, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch:  3 tensor(0.0613, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch:  4 tensor(0.0586, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch:  5 tensor(0.0445, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch:  6 tensor(0.0386, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch:  7 tensor(0.0364, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch:  8 tensor(0.0379, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch:  9 tensor(0.0371, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def add_noise(image):\n",
    "    noise_factor = 0.5\n",
    "    noisy_image = image + noise_factor * torch.randn_like(image)\n",
    "    noisy_image = torch.clamp(noisy_image, 0, 1)\n",
    "    return noisy_image\n",
    "\n",
    "class PairedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, original_dataset):\n",
    "        self.original_dataset = original_dataset\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.original_dataset[index]\n",
    "        noisy_image = add_noise(image)\n",
    "        return image, noisy_image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.original_dataset)\n",
    "\n",
    "# Dataset and loader setup\n",
    "original_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "original_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=original_transform)\n",
    "\n",
    "paired_dataset = PairedDataset(original_dataset)\n",
    "train_loader = DataLoader(paired_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "model = Autoencoder().to(device)\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.0001)\n",
    "\n",
    "for epoch in range(10):  # Adjust the number of epochs\n",
    "    # Modify the training loop to use noisy images as input\n",
    "    for images, noisy_images, _ in train_loader:\n",
    "        noisy_images = noisy_images.to(device)\n",
    "        images = images.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(noisy_images)\n",
    "        loss = criterion(outputs, images)  # Target is the original image\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"Epoch: \", epoch, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ddfaf4ad-8b0b-476d-a9a0-1bd6287fc3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHkAAAIQCAYAAAAVR7JwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB92klEQVR4nO3deXxU1f3/8U8SkglLEpZAQoBAQAQFv1CRYBQENV9xZZFVLYKiqASQRVuxIoq2UVRIVRQXCvpFFsGC2kVL2Swti6BIEUFFViFh0SwECCE5vz/8MTpzDnAzmcnce/N6Ph7zeHg/OXPnTDLvnHCc+dwIpZQSAAAAAAAAOFpkuCcAAAAAAACAymOTBwAAAAAAwAXY5AEAAAAAAHABNnkAAAAAAABcgE0eAAAAAAAAF2CTBwAAAAAAwAXY5AEAAAAAAHABNnkAAAAAAABcgE0eAAAAAAAAF2CTJ0yeeOIJiYiICOi+c+bMkYiICNm9e3dwJ/ULu3fvloiICJkzZ07IHgNwKvILOBsZBpyL/ALORoZDj02eAHz55Zfy61//Wpo0aSIej0dSUlLkjjvukC+//DLcUwNwHuQXcDYyDDgX+QWcjQw7Q4RSSoV7Ek7y5z//WW677TapX7++DB8+XNLS0mT37t0ya9YsOXr0qCxYsED69u173vOcPn1aTp8+LbGxsRWeQ1lZmZSWlorH4wl4F/R8du/eLWlpaTJ79mwZNmxYSB4DqGrkF3A2Mgw4F/kFnI0MO0eNcE/ASXbu3ClDhgyRli1byieffCINGzb0fu3BBx+Ubt26yZAhQ2TLli3SsmVL4zmKi4uldu3aUqNGDalRI7Bvf1RUlERFRQV0X6C6Ir+As5FhwLnIL+BsZNhZ+LhWBTz33HNy/Phxef31131e2CIiiYmJ8tprr0lxcbFMnTpVRH7+vOG2bdvk9ttvl3r16knXrl19vvZLJ06ckDFjxkhiYqLExcVJr1695Pvvv5eIiAh54oknvONMn0Vs0aKF3HzzzbJmzRpJT0+X2NhYadmypbz99ts+j/HDDz/IQw89JJdcconUqVNH4uPj5YYbbpAvvvgiiN8pwH7IL+BsZBhwLvILOBsZdhbeyVMBH374obRo0UK6detm/PpVV10lLVq0kL/+9a8+9QEDBkjr1q3lD3/4g5zr03HDhg2Td999V4YMGSKXX365rF69Wm666SbL8/v222+lf//+Mnz4cBk6dKj86U9/kmHDhkmnTp2kXbt2IiLy3XffydKlS2XAgAGSlpYmeXl58tprr0n37t1l27ZtkpKSYvnxACchv4CzkWHAucgv4Gxk2GEULMnPz1cionr37n3Ocb169VIiogoLC9XkyZOViKjbbrtNG3fma2ds2rRJiYgaO3asz7hhw4YpEVGTJ0/21mbPnq1ERO3atctba968uRIR9cknn3hrhw4dUh6PR02YMMFbO3nypCorK/N5jF27dimPx6OmTJniUxMRNXv27HM+X8AJyC/gbGQYcC7yCzgbGXYePq5lUVFRkYiIxMXFnXPcma8XFhZ6a/fff/95z//RRx+JiMjIkSN96qNHj7Y8x4svvthnd7Vhw4bSpk0b+e6777w1j8cjkZE//djLysrk6NGjUqdOHWnTpo189tlnlh8LcBLyCzgbGQaci/wCzkaGnYdNHovOvGjPvMjPxhSCtLS0855/z549EhkZqY294IILLM8xNTVVq9WrV09+/PFH73F5eblMnz5dWrduLR6PRxITE6Vhw4ayZcsWKSgosPxYgJOQX8DZyDDgXOQXcDYy7Dxs8liUkJAgjRs3li1btpxz3JYtW6RJkyYSHx/vrdWsWTPU0xMROWuncfWLzz/+4Q9/kPHjx8tVV10lc+fOlY8//liWLVsm7dq1k/Ly8iqZJ1DVyC/gbGQYcC7yCzgbGXYeGi9XwM033yxvvPGGrFmzxtsd/Jf+9a9/ye7du+W+++6r8LmbN28u5eXlsmvXLmndurW3/u2331Zqzv4WL14sV199tcyaNcunnp+fL4mJiUF9LMBOyC/gbGQYcC7yCzgbGXYW3slTAQ8//LDUrFlT7rvvPjl69KjP13744Qe5//77pVatWvLwww9X+Nw9e/YUEZFXXnnFp/7SSy8FPmGDqKgorbP5okWL5Pvvvw/q4wB2Q34BZyPDgHORX8DZyLCz8E6eCmjdurW89dZbcscdd8gll1wiw4cPl7S0NNm9e7fMmjVLjhw5IvPnz5dWrVpV+NydOnWSfv36SU5Ojhw9etR76bivv/5aREQiIiKC8hxuvvlmmTJlitx1111yxRVXyH//+1955513pGXLlkE5P2BX5BdwNjIMOBf5BZyNDDsLmzwVNGDAAGnbtq1kZ2d7X9ANGjSQq6++Wh599FFp3759wOd+++23JTk5WebPny9LliyRzMxMWbhwobRp00ZiY2ODMv9HH31UiouLZd68ebJw4UK59NJL5a9//as88sgjQTk/YGfkF3A2Mgw4F/kFnI0MO0eE8n/PEmxl8+bN8qtf/Urmzp0rd9xxR7inA6ACyC/gbGQYcC7yCzgbGQ4cPXls5MSJE1otJydHIiMj5aqrrgrDjABYRX4BZyPDgHORX8DZyHBw8XEtG5k6daps2rRJrr76aqlRo4b8/e9/l7///e8yYsQIadasWbinB+AcyC/gbGQYcC7yCzgbGQ4uPq5lI8uWLZMnn3xStm3bJseOHZPU1FQZMmSI/O53v5MaNdiPA+yM/ALORoYB5yK/gLOR4eBikwcAAAAAAMAF6MkDAAAAAADgAiHb5JkxY4a0aNFCYmNjpUuXLrJhw4ZQPRSAICO/gLORYcC5yC/gbGQY4RaSj2stXLhQ7rzzTpk5c6Z06dJFcnJyZNGiRbJjxw5p1KjROe9bXl4uBw4ckLi4OImIiAj21OBwSikpKiqSlJQUiYzkjWihUJn8ipBhnBsZDj3WYIQK+Q091mCEEhkOPdZghEqF8qtCID09XWVlZXmPy8rKVEpKisrOzj7vffft26dEhBu3c9727dsXipcuVOXyqxQZ5mbtRoZDhzWYW6hv5Dd0WIO5VcWNDIcOazC3UN+s5DfoW7inTp2STZs2SWZmprcWGRkpmZmZsnbt2vPePy4uLthTggvxOgmNyuZXhJ8NrOF1EhqswagKvE5CgzUYVYXXSWiwBqMqWHmdBP16ZEeOHJGysjJJSkryqSclJcn27du18SUlJVJSUuI9LioqCvaU4EK8hTE0KppfETKMwJDh0GANRlUgv6HBGoyqQoZDgzUYVcFKfsP+Yczs7GxJSEjw3po1axbuKQGoADIMOBf5BZyNDAPORX4RKkHf5ElMTJSoqCjJy8vzqefl5UlycrI2fuLEiVJQUOC97du3L9hTAmBRRfMrQoYBO2ENBpyLNRhwNtZg2EXQN3liYmKkU6dOsnz5cm+tvLxcli9fLhkZGdp4j8cj8fHxPjcA4VHR/IqQYcBOWIMB52INBpyNNRh2EfSePCIi48ePl6FDh8pll10m6enpkpOTI8XFxXLXXXeF4uEABBH5BZyNDAPORX4BZyPDsIOQbPIMGjRIDh8+LI8//rjk5uZKx44d5aOPPtKaUAGwH/ILOBsZBpyL/ALORoZhBxFKKRXuSfxSYWGhJCQkhHsasLmCggLe0mhTZBhWkGF7Ir+wgvzaFxmGFWTYnsgvrLCS37BfXQsAAAAAAACVF5KPawEAAABAIDp27OhzvGLFCm3M999/r9WuvfZarXbo0KGgzQsAnIB38gAAAAAAALgAmzwAAAAAAAAuwCYPAAAAAACAC7DJAwAAAAAA4AI0XgYAAABgG2PGjPE5Nl1W2lR75ZVXtFr//v2DNzEAcADeyQMAAAAAAOACbPIAAAAAAAC4AJs8AAAAAAAALkBPHgdo1qyZVlu4cKGl+y5atMjnePr06UGZEwAAAFBZs2bN0mp33nlnQOfq1auXVuvYsaNW27x5c0DnBwAn4J08AAAAAAAALsAmDwAAAAAAgAuwyQMAAAAAAOACbPIAAAAAAAC4AI2XbcZqk+WMjAxL5/Mf17RpU23MhAkTLM4OAAAACB5Ts+SIiIiAzhUVFWWpBgBuxjt5AAAAAAAAXIBNHgAAAAAAABdgkwcAAAAAAMAF2OQBAAAAAABwARov28zYsWO1mtUmy1aMHz9eq9F4GQiMqZmjKcP33HOPVjt9+rRWe++997Ta888/73N87NixCswQQCi0adNGqz3xxBNabfDgwec914gRI7TaG2+8EdC8ALu79957tVrdunWDdv6PP/5Yq23ZsiVo5wdQtV544QWtNmDAAK1munjRvn37fI4HDhyojVm3bl0lZmdfvJMHAAAAAADABdjkAQAAAAAAcAE2eQAAAAAAAFyATR4AAAAAAAAXoPFyGJkaSZkaI1u1du3a847Zv39/wOcHqrP+/ftrtSlTpmi1iy66yNL5SkpKtNrjjz+u1Xr06OFzfMMNN2hjTpw4YekxAfysZs2aWq1GDf3PojvuuEOrTZw4Uas1bdpUq5WXl593Hp07d9ZqNF6GW5kuJhIZGbz/57xhwwatVlpaGrTzAwgOU6PkhQsXarXKXIDI/zFSU1O1MTReBgAAAAAAgG2xyQMAAAAAAOACbPIAAAAAAAC4AJs8AAAAAAAALkDj5TCqTCOpRYsWabUJEyZoNf/mzosXLw74MYHqpGPHjj7Hb775pjYmISFBq5karX766adarXfv3lrt+eef12rt2rXzOfZ4PNoYGi8D59ayZUut9vHHH1saZ5Wpuat/g/U6depoY6ZOnRrwYwJ2du+992q1IUOGBO38N954o1ZbtWpV0M4PIHSsNlk2XVjIdKGiAQMGWBpXXfBOHgAAAAAAABdgkwcAAAAAAMAF2OQBAAAAAABwATZ5AAAAAAAAXIDGy1XEvwGyiPXGy/v27dNqAwcOtHRf/2ZVe/futXQ/oDqJjNT3u/v06eNzbGqyXFhYqNUGDx6s1f7+979bmkdUVJRW82+qnJ+fb+lcQHVWo4bvnzfTpk3Txlhtsnzq1CmttnHjRq32hz/8QavFxsb6HJsufmBqxgy4Qb169bSaab21Yv/+/Vpt69atWs2/2TmA8Hv33Xe1mtUmy4MGDbJ0X1PjZf8LFZnm4Va8kwcAAAAAAMAF2OQBAAAAAABwgQpv8nzyySdyyy23SEpKikRERMjSpUt9vq6Ukscff1waN24sNWvWlMzMTPnmm2+CNV8AlUB+AWcjw4BzkV/A2cgwnKLCmzzFxcXSoUMHmTFjhvHrU6dOlRdffFFmzpwp69evl9q1a0vPnj3l5MmTlZ4sgMohv4CzkWHAucgv4GxkGE5R4cbLN9xwg9xwww3GrymlJCcnRx577DHp3bu3iIi8/fbbkpSUJEuXLjU2JHWrZs2a+RybmkFZNX369LDcF+5Dfs1SU1O12uTJk32Oi4qKtDEPPfSQVrPaZNlk586dWm3Pnj0Bnw/uQ4at6dixo8/xLbfcYul+pqatv/nNb7Tayy+/bOl8s2bNOu+YhQsXajVTE+e33nrL0mPCvqpbfi+44IKgncuUpe+//z5o57cqLi5Oq9WuXVur5ebmarX27dtrNdMFHLhIin1VtwwHyv8CQVb/HWy1yfLzzz+v1fz/7S0ism7duvOOMV3gyA2C2pNn165dkpubK5mZmd5aQkKCdOnSxdgtW+SnP6gKCwt9bgCqXiD5FSHDgF2wBgPOxRoMOBtrMOwkqJs8Z3atk5KSfOpJSUnGHW0RkezsbElISPDeTDtsAEIvkPyKkGHALliDAediDQacjTUYdhL2q2tNnDhRCgoKvDe3vmUKcCsyDDgX+QWcjQwDzkV+ESoV7slzLsnJySIikpeXJ40bN/bW8/LytM/Hn+HxeMTj8QRzGrYwduxYn2OrO7OLFi3SavTVQVUIJL8i7sjwuHHjzjtm//79Wu2NN94I6jxmzpyp1RITE4P6GHCv6roGR0dHa7Xf/e53AZ1r+fLlWs3Uf8fUg6NJkyZaLT09/byPaepb0rZt2/PeD+7i9DX4rrvu0mp333130M7/9ttvB+1cIiKdOnXSapdccolWGz58uM+xKfs1a9bUakeOHNFqpqwfO3ZMq5l68vh/f+nbYz/VdQ028f93sImp/45pk8vUt87qv6v9ewFNmzbN0mO6QVDfyZOWlibJyck+fyQVFhbK+vXrjU2TANgH+QWcjQwDzkV+AWcjw7CTCr+T59ixY/Ltt996j3ft2iWbN2+W+vXrS2pqqowdO1aefvppad26taSlpcmkSZMkJSVF+vTpE8x5AwgA+QWcjQwDzkV+AWcjw3CKCm/ybNy4Ua6++mrv8fjx40VEZOjQoTJnzhz5zW9+I8XFxTJixAjJz8+Xrl27ykcffSSxsbHBmzWAgJBfwNnIMOBc5BdwNjIMp6jwJk+PHj1EKXXWr0dERMiUKVNkypQplZoYgOAjv4CzkWHAucgv4GxkGE4R1MbL+Fmgl8BbvHhxkGcC4Jfi4+O12m233abVioqKfI5vv/32oM7D/xKbIiJz587Vav7NIUeNGqWNCXZDSsBJGjZsqNWuuuqqgM5VWFio1W666Sat9tBDDwXtMfPz87Xaiy++GNC5gHB57LHHtFpERETA5/vb3/7mc3yuy8j/UoMGDbRaTk6OVrv55pu1munvg0BdeOGFlsY1atRIq7Vs2VKrPfzwwz7HU6dO1ca4tYEsnMdKD6J3331Xqw0cODCgc52NfybWrVsX8LmcJuyXUAcAAAAAAEDlsckDAAAAAADgAmzyAAAAAAAAuACbPAAAAAAAAC5A42WbMTWhAhA8psaqX331lVZLS0vzOd68eXPAj2lqrPjKK69otR49epz3XMOHD9dqNF5GdXbgwAGt9uabb/ocmxolmwwePNhSLVA//vijVjM1fj948GDQHhOoCv5rpoic8ypE5+PfaPnkyZPamPr162s103p4/fXXBzwPuxg5cqTPsakR9e9///uqmg5QaaZ/815++eVBfQyra78b8U4eAAAAAAAAF2CTBwAAAAAAwAXY5AEAAAAAAHABNnkAAAAAAABcgMbLYTRt2rRwTwGAiBw7dixo52rRooVWM2W9b9++AZ1/6dKlAd0PqE6mTJnic2xq0Nq5c2etdskll4RsTiLmxunLli0L6WMCVSEiIkKrVabx8rx58847ZtasWVotHE2W9+7dq9WOHz+u1dq2bVsV0wHCbu3atT7HGRkZ2pgBAwYEdK6znc/ElM3qgnfyAAAAAAAAuACbPAAAAAAAAC7AJg8AAAAAAIALsMkDAAAAAADgAjReDpGmTZued8z69eurYCYAzmfChAlabcuWLT7Hv//977UxpobNY8eO1WqNGjUKeG5Hjx71OZ4zZ07A5wKqi+LiYp/je++9VxsTHx+v1dLT07XaM888o9V+9atfWZqHf/PY5cuXW7of4DSVabJssn379vOOqUwjY1ND1h07dmi1N99887znWrdunVaLjY3VavPnz9dql1566XnPDzjNFVdc4XM8cOBAS/czNVl+4YUXLN130aJFWs2UzeqCd/IAAAAAAAC4AJs8AAAAAAAALsAmDwAAAAAAgAuwyQMAAAAAAOACNF4OoyZNmmi1yy+/PKiPUZ0bTgFW7dy5U6tlZGT4HJsaKt9yyy1araCgQKv961//0mrt2rXTavXr19dq/s0hi4qKtDEAgsN00YS0tLSAz+ffMNLUrB2AbtiwYT7HpqbF0dHRAZ9/1KhRWu2vf/2rVvN4PD7HjRs31sYMGTJEq91zzz1arUWLFhWYIeAe7777rqVxzZo102oDBgywdN9p06ZVaE5uxzt5AAAAAAAAXIBNHgAAAAAAABdgkwcAAAAAAMAF2OQBAAAAAABwARovh8j+/fvPO6YqGkStXbvW53jQoEHamH379oV8HoCdlZaWarVNmzb5HJsaK5oaMJoaq5qarG/ZssXS3JYsWeJzfPr0aUv3A3BuN9xwg1abNWtWwOd76623tNo333wT8PkAJ4mIiNBqSqmAz/f000+f87iyZs6cqdU+/vhjrZaYmOhzbLrgAoDgMF3kxGTRokVajYsN+eKdPAAAAAAAAC7AJg8AAAAAAIALsMkDAAAAAADgAvTkCZHFixf7HA8YMCAs88jIyPA5XrhwoTYmJydHq7377ruhmhLgGgcPHrQ0ztS7Jzo6WquZ+vm88847FZ8YAB/x8fFazepn/03Wr1+v1UaPHq3ViouLA34MwEkWLFig1QYOHBiGmViTkpKi1e66664wzERn6mU0f/58n+OPPvqoqqYDhESzZs20mtV/L1dFX1un4508AAAAAAAALsAmDwAAAAAAgAuwyQMAAAAAAOACbPIAAAAAAAC4AI2XQ8S/cfHzzz+vjTE1nNq3b59WW7dunaXHvPzyy8/7GP6NmM+GxstA8FxzzTWWxm3btk2rfffdd8GeDlDt/P73v9dq6enplu57+PBhrfab3/xGq9FkGdXZbbfdptVuvPFGrVanTp2qmI5jmJosz507V6sNGzasCmYDVB3TxQ+C/W/j6ox38gAAAAAAALgAmzwAAAAAAAAuUKFNnuzsbOncubPExcVJo0aNpE+fPrJjxw6fMSdPnpSsrCxp0KCB1KlTR/r16yd5eXlBnTSAwJBhwLnIL+BsZBhwLvILJ6nQJs/q1aslKytL1q1bJ8uWLZPS0lK57rrrfD6HPm7cOPnwww9l0aJFsnr1ajlw4IDceuutQZ84gIojw4BzkV/A2cgw4FzkF04SoUwdvyw6fPiwNGrUSFavXi1XXXWVFBQUSMOGDWXevHnSv39/ERHZvn27XHTRRbJ27VpjY2B/hYWFkpCQEOiUbOuFF17QauPHj9dq06ZN02oTJkyw9Bjjxo2zdD5/poZWqamplh4zXAoKCiQ+Pj7c03A8Mlw1nnrqKa322GOPabUNGzZotS5duoRkTuFGhiuP/Fo3f/58rTZw4ECtduTIEa3Wr18/rbZmzZrgTMyhyG9wuD3Dpubmv/3tb7XazTffrNVq1HDOtWFOnz6t1crLy7XakiVLtNp//vMfrfbyyy8HZ2LnQIYrz+35DSZTQ+W9e/dauu+gQYO0WnW/QJCV/FaqJ09BQYGIiNSvX19ERDZt2iSlpaWSmZnpHdO2bVtJTU2VtWvXVuahAIQAGQaci/wCzkaGAeciv7CzgLfJy8vLZezYsXLllVdK+/btRUQkNzdXYmJipG7duj5jk5KSJDc313iekpISKSkp8R4XFhYGOiUAFUCGAeciv4CzkWHAucgv7C7gd/JkZWXJ1q1bZcGCBZWaQHZ2tiQkJHhvprdzAQg+Mgw4F/kFnI0MA85FfmF3AW3yjBo1Sv7yl7/IypUrpWnTpt56cnKynDp1SvLz833G5+XlSXJysvFcEydOlIKCAu/N1B8GQHCRYcC5yC/gbGQYcC7yCyeo0Me1lFIyevRoWbJkiaxatUrS0tJ8vt6pUyeJjo6W5cuXexsV7tixQ/bu3SsZGRnGc3o8HvF4PAFO3zlMzZNN3xNTzdS0ecCAAVot0N3f6dOnB3Q/OA8ZDo+OHTtaGvfhhx+GdiJwNPJrXd++fX2OTY1djx49qtVycnK0WnVvsozgqW4ZNl1MwNTIvFOnTlrt0Ucf9Tnu06dP0OZ1NqZGsG+++eZ57/fee+9pte3btwdlTrCP6pbfYBo7dqylcYsWLdJq1b3JcqAqtMmTlZUl8+bNk/fff1/i4uK8ny9MSEiQmjVrSkJCggwfPlzGjx8v9evXl/j4eBk9erRkZGRY6igOILTIMOBc5BdwNjIMOBf5hZNUaJPn1VdfFRGRHj16+NRnz54tw4YNE5Gf3hUSGRkp/fr1k5KSEunZs6e88sorQZksgMohw4BzkV/A2cgw4FzkF05S4Y9rnU9sbKzMmDFDZsyYEfCkAIQGGQaci/wCzkaGAeciv3CSgK+uBQAAAAAAAPuo0Dt5EFyDBg3SagsXLtRq48ePD9pjmhpaLV68OGjnB6q7tm3barUbb7zR0n1LSkqCPR3A9UwXHZg7d67PcWxsrDZmx44dWi07Ozt4EwNgyaZNm7SaqUEzAGfwX5dNFwwymTZtWiimUy3xTh4AAAAAAAAXYJMHAAAAAADABdjkAQAAAAAAcAE2eQAAAAAAAFyAxsthtG/fPq1masb873//W6vt379fq5maKk+fPj3A2QEIRGSkvnduqpksWbIk2NMBXC8qKkqrmRotAwCA0Bs7dqzPsekCCaYmy+vWrQvVlKod3skDAAAAAADgAmzyAAAAAAAAuACbPAAAAAAAAC7AJg8AAAAAAIAL0HjZZkzNmFNTU8MwEwCBaNKkiaVxBQUFWq2oqCjY0wFcLyMjI9xTAACgWjI1VR4/fvx575eTkxOC2eAM3skDAAAAAADgAmzyAAAAAAAAuACbPAAAAAAAAC5ATx4ACCKr/UF27typ1fLy8oI9HcD11q9ff94xhw8f1mqzZs0KxXQAAKg2XnjhhfOOmTZtmlYz9aFF8PBOHgAAAAAAABdgkwcAAAAAAMAF2OQBAAAAAABwATZ5AAAAAAAAXCBCKaXCPYlfKiwslISEhHBPAzZXUFAg8fHx4Z4GDMgwrCDD9kR+YQX5tS8yDCvIsD2RX1hhJb+8kwcAAAAAAMAF2OQBAAAAAABwATZ5AAAAAAAAXIBNHgAAAAAAABdgkwcAAAAAAMAF2OQBAAAAAABwATZ5AAAAAAAAXIBNHgAAAAAAABew3SaPUircU4AD8DqxL342sILXiT3xc4EVvE7si58NrOB1Yk/8XGCFldeJ7TZ5ioqKwj0FOACvE/viZwMreJ3YEz8XWMHrxL742cAKXif2xM8FVlh5nUQom20ZlpeXy4EDByQuLk6KioqkWbNmsm/fPomPjw/31CqssLDQ0fMXsd9zUEpJUVGRpKSkSGSk7fYoIT9nWCklqamptnntBMJur/+KsuP8ybC9sQbbi92eA/m1P9Zg+7Dj/MmwvbEG24vdnkNF8lujiuZkWWRkpDRt2lRERCIiIkREJD4+3hbf2EA5ff4i9noOCQkJ4Z4CzuFMhgsLC0XEXq+dQDn9Odht/mTYvliD7clOz4H82htrsP3Ybf5k2L5Yg+3JTs/Ban7ZwgUAAAAAAHABNnkAAAAAAABcwNabPB6PRyZPniwejyfcUwlIMOffo0cP6dGjR+UnVUFO/xkgfNzw2gnWcyC/cCKnv35Yg1GdueG14/QMu+FngPBx+uvH6fkVcfbPwHaNl51uzpw5ctddd4nH45GdO3dKkyZNfL7eo0cPOXLkiGzdurVC5z3zwl61alWQZgrAH/kFnI0MA85GhgHnIr/2Yet38jhZSUmJPPPMM0E73z/+8Q/5xz/+EbTzATg78gs4GxkGnI0MA85FfsOPTZ4Q6dixo7zxxhty4MCBoJwvJiZGYmJignIuAOdGfgFnI8OAs5FhwLnIb/ixyRMijz76qJSVlZ13F/P06dPy1FNPSatWrcTj8UiLFi3k0UcflZKSEp9xps8ivvTSS9KuXTupVauW1KtXTy677DKZN2+eiIisXLlSIiIiZMmSJdpjzps3TyIiImTt2rWVe5KAS5FfwNnIMOBsZBhwLvIbfmzyhEhaWprceeed593FvOeee+Txxx+XSy+9VKZPny7du3eX7OxsGTx48DnP/8Ybb8iYMWPk4osvlpycHHnyySelY8eOsn79ehH5KQzNmjWTd955R7vvO++8I61atZKMjIzKPUnApcgv4GxkGHA2Mgw4F/m1AWVTL7/8smrevLnyeDwqPT1drV+/PtxTOqvVq1erm2++WTVu3FiJiBIR9emnn6qdO3eqGjVqqNGjR6tJkyap5ORkFRERoWrXrq2+/vprtXnzZiUi6p577vE530MPPaRERK1YscJb6969u+revbv3uHfv3qpdu3bnnNfEiROVx+NR+fn53tqhQ4dUjRo11OTJk721P/zhD+qyyy5TderUUQ0bNlS9e/dW27dv9znXiRMn1MiRI1X9+vVV7dq11a233qpyc3MD+G6hunBihhMSEpSIqOeee86b3zFjxqjy8nI1adIkFR0drSIiItS1116r3n//fVvkVykyjOBzYn5Zg4GfkWEyDOciv+S3smy5ybNgwQIVExOj/vSnP6kvv/xS3Xvvvapu3boqLy8v3FMz+tvf/qZ+97vfqT//+c8+L26llLrrrrtUjRo1VFxcnFq6dKm67LLLVFxcnEpLS1NTpkxRIqK2bdvmc76DBw8qEVETJkzw1vxf3EOHDlUJCQlqw4YNZ53XV199pUREvfnmm97aSy+9pEREffPNN95az5491ezZs9XWrVvV5s2b1Y033qhSU1PVsWPHvGPuv/9+1axZM7V8+XK1ceNGdfnll6srrrgi4O8Z3M2pGR41apR3k0epn/IbGxurHn30UZWQkKDatWunWrVqpXr16qXq1atni/wqRYYRXE7NL2sw8BMyTIbhXOSX/AaDLTd50tPTVVZWlve4rKxMpaSkqOzs7DDOyhr/F/e3336rRER17dpVKfXTi/Siiy5SHo9HXXvttSoyMlKdOnVKO0/dunVV//79vcf+L+5t27apJk2aKBFRF1xwgRo5cqRas2aNdp7OnTurq6++2nt8+eWXq8svv/ycz+HQoUNKRNTq1auVUkrl5+er6OhotWjRIu+YM8FZu3athe8KqhunZnj27Nk+mzxn/i9ErVq11HPPPae6d++u2rVrp/Lz81VkZKSKiIiwXX6VIsOoHKfmVynWYEApMqwUGYZzkV/yGwy268lz6tQp2bRpk2RmZnprkZGRkpmZ6cgGSRERESIi8umnn8rBgwdF5Kfn06VLF8nLy/MZUxEXXXSR7NixQxYsWCBdu3aV9957T7p27SqTJ0/2GXfnnXfK6tWrZf/+/bJz505Zt26d/PrXvz7nuQsKCkREpH79+iIismnTJiktLfX5mbRt21ZSU1Md+TNBaLkpwy1btpTevXvL8ePHpUOHDt56QkKCJCUliYj98itChhE4N+VXhDUY1Q8ZtoYMw47IrzXk9/xst8lz5MgRKSsr8/4D6oykpCTJzc0N06wCd2bOZWVl8uyzz3rrSUlJEhERIeXl5fLNN9/43CcvL0/y8/OlefPm5zx37dq1ZdCgQTJ79mzZu3ev3HTTTfL73/9eTp486R0zePBgiYqKkvnz58s777wj0dHRMmjQoLOes7y8XMaOHStXXnmltG/f3vscYmJipG7duj5jnfozQWi5LcMDBw4UEZF3333Xp96gQQNRStkqvyJkGJXjtvyyBqO6IcNkGM5FfslvsNhuk8etbr31Vnnttdd8XgyNGzcWEZGcnByfsdOmTRMRkZtuuums5zt69KjPcUxMjFx88cWilJLS0lJvPTExUW644QaZO3euvPPOO3L99ddLYmLiWc+blZUlW7dulQULFlh+boCbNW3aVERE5s6da/v8ipBhwIQ1GHA2Mgw4F/mtejXCPQF/iYmJEhUV5X0L1xl5eXmSnJwcplkF7syc77jjDnnvvfdkx44d0q5dO8nLy5OOHTtK48aN5fXXX5f8/Hzp3r27bNiwQd566y3p06ePXH311Wc973XXXSfJycly5ZVXSlJSknz11Vfy8ssvy0033SRxcXE+Y++8807p37+/iIg89dRTZz3nqFGj5C9/+Yt88skn3n/YnnkOp06dkvz8fJ9dTKf+TBBabs1waWmpN78iIiUlJXLRRRfZJr8iZBiV59b8sgajuiDDZBjORX7Jb9CEsyHQ2aSnp6tRo0Z5j8vKylSTJk0c2XCqvLxcJScnq+eff14NHTpUiYi34dT8+fNVaWmpevLJJ1VaWpqKjo5WzZo1UxMnTlQnT570Oa9/w6nXXntNXXXVVapBgwbK4/GoVq1aqYcfflgVFBRocyopKVH16tVTCQkJ6sSJE9rXy8vLVVZWlkpJSVFff/219vUzDacWL17srW3fvt32DacQPk7NsH/jZaV+zvBll12mRES1a9dOFRQUKI/Ho+bOnRv2/J6ZIxlGsDg1v0qxBgNKkWEyDCcjv+Q3GGy5ybNgwQLl8XjUnDlz1LZt29SIESNU3bp1bXs9+qKiIvX555+rzz//XImImjZtmvr888/Vnj17lFJKPfPMM6pu3brq/fffV1u2bFG9e/dWaWlpZ/0HW7CVlpaqhg0bqrvvvtv49QceeEAlJCSoVatWqYMHD3pvx48f9465//77VWpqqlqxYoXauHGjysjIUBkZGVUyfzgPGQ6e8+VXKTKM4CK/wcUajKpGhoOLDKMqkd/gqq75teUmj1I/Xcc+NTVVxcTEqPT0dLVu3bpwT+msVq5c6d25/OVt6NChSqmfdggnTZqkkpKSvJeM27FjR5XNb9GiRUpE1KpVq4xfN81dRNTs2bO9Y06cOKFGjhyp6tWrp2rVqqX69u2rDh48WEXPAE5EhoPjfPlVigwj+Mhv8LAGIxzIcPCQYVQ18hs81TW/EUopVbEPeMEp1q9fL1u2bJGnnnpKEhMT5bPPPgv3lABYRH4BZyPDgLORYcC5qnt+ubqWi7366qvywAMPSKNGjeTtt98O93QAVAD5BZyNDAPORoYB56ru+eWdPAAAAAAAAC7AO3kAAAAAAABcIGSbPDNmzJAWLVpIbGysdOnSRTZs2BCqhwIQZOQXcDYyDDgX+QWcjQwj3ELyca2FCxfKnXfeKTNnzpQuXbpITk6OLFq0SHbs2CGNGjU6533Ly8vlwIEDEhcXJxEREcGeGhxOKSVFRUWSkpIikZG8ES0UKpNfETKMcyPDoccajFAhv6HHGoxQIsOhxxqMUKlQfkNxya709HSVlZXlPS4rK1MpKSkqOzv7vPfdt2/fWS9lxo3bmdu+fftC8dKFqlx+lSLD3KzdyHDosAZzC/WN/IYOazC3qriR4dBhDeYW6puV/AZ9C/fUqVOyadMmyczM9NYiIyMlMzNT1q5de977x8XFBXtKcCFeJ6FR2fyK8LOBNbxOQsNNa3B0dLR2gz3Y6XXiJqzBqCq8TkLDTWuw07Ru3Vq7uZWV10mNYD/okSNHpKysTJKSknzqSUlJsn37dm18SUmJlJSUeI+LioqCPSW4EG9hDI2K5leEDCMwZDg03LQG8xqxL342ocEajKpChkPDTWuw00RFRYV7ClXGSn7D/mHM7OxsSUhI8N6aNWsW7ikBqAAyDDgX+QWcjQwDzkV+ESpB3+RJTEyUqKgoycvL86nn5eVJcnKyNn7ixIlSUFDgve3bty/YUwJgUUXzK0KGATthDQacizUYcDbWYNhF0Dd5YmJipFOnTrJ8+XJvrby8XJYvXy4ZGRnaeI/HI/Hx8T43AOFR0fyKkGHATty0Bp86dUq7BeqGG27QboDdsAYDzuamNdhptm/frt2qs6D35BERGT9+vAwdOlQuu+wySU9Pl5ycHCkuLpa77rorFA8HIIjIL+BsZBhwLvILOBsZhh2EZJNn0KBBcvjwYXn88cclNzdXOnbsKB999JHWhAqA/ZBfwNnIMOBc5BdwNjIMO4hQSqlwT+KXCgsLJSEhIdzTgM0VFBTwlkabIsOwggzbk1vza/p41t///vcwzMQdyK99uTXDCC4ybE/kF1ZYyW/Yr64FAAAAAACAygvJx7UAAADsgnftAM5m+uBBREREGGaiu+2227Ta/PnzAz5fjx49tNqqVasCPh+cLyYmRqtV5mIEcD/eyQMAAAAAAOACbPIAAAAAAAC4AJs8AAAAAAAALsAmDwAAAAAAgAvQeBkAAACAbeTn5/scd+7cWRtjasZsEuoGzZVpsmxCk2X4o8kyKop38gAAAAAAALgAmzwAAAAAAAAuwCYPAAAAAACAC9CTx6G2bdum1S6++GKt1rdvX5/jJUuWhGxOAADYUZ8+fbTa0qVLq3wegNM0btxYqx08eDCoj1Gjhv7PkYSEBJ/jTz/9VBtz2223abW2bdsGb2KATaSmpmq1vXv3hmEmcAreyQMAAAAAAOACbPIAAAAAAAC4AJs8AAAAAAAALsAmDwAAAAAAgAtEKKVUuCfxS4WFhVqzNeis/thOnz7tc7xr1y5tzIUXXhiUOVWlgoICiY+PD/c0YECGQ8v0ui8sLAzDTCqHDNsT+YUV5Ne+nJjhUP9TpEOHDlpty5YtIX1MuyPD9uTE/DpJvXr1tNqPP/4YhplUjpX88k4eAAAAAAAAF2CTBwAAAAAAwAXY5AEAAAAAAHABNnkAAAAAAABcoEa4J1AZHTt21GqbN2+u8nmE2vXXX6/VXnzxRa02ZswYrXbgwAGfYyc2WQacZNq0aVrN4/FotZtuukmrtWjR4rznd2KTZaA6MDWPnTNnjs/x119/rY3Jzs4O1ZQA23nhhRcCul9qaqpW27t3r6X7Vvcmy4DbmNbbEydOaLWtW7f6HKenp4dsTmfYpbkz7+QBAAAAAABwATZ5AAAAAAAAXIBNHgAAAAAAABdgkwcAAAAAAMAFHN142Y1Nlk2NpJo3b67VXn75Za0WERGh1aZPnx6ciQHQDBw4UKuNGzcu4PMdOnRIqzVs2NDn2JRzAFXLtFa/+eabWu2ee+4577lMf8v8/e9/D2heZ9OvXz+f4/feey+o54f9REdH+6wXp06dCuNsfrZs2TKtNn78+PPez9Rk+YknntBqTz75ZEDzCrZXX31Vqz3wwANhmAngHDNnztRq9913n1YrLy/XajVr1tRqPXv2DM7EKiAcTZZNeCcPAAAAAACAC7DJAwAAAAAA4AJs8gAAAAAAALgAmzwAAAAAAAAu4OjGyya9evXyOf7ggw/CNJPg2bNnj1az2nz1/fff9zk2fT/8v2dVoVWrVlpt586dVT4PuFt6erpW27BhQ0DnGj16tFbzeDxazZTNP/7xj1rtwQcf1GoPP/ywVnvrrbesThFwvSZNmmi177//PqBzmZonm+Tk5Fga9+GHH2q166+//rxjgt1k2YRGy9VPaWlpuKdgZHq9/+1vf9NqN954o8+xaQ02XYRk0KBBWm3hwoWW5tanTx+ttnTpUkv39WeXJstvvPGGz/GJEydkzJgxYZoN8DPT37z/8z//o9VMjZdff/11rWZa0+3SBDkceCcPAAAAAACAC7DJAwAAAAAA4AJs8gAAAAAAALgAmzwAAAAAAAAuEKGsdh6sIoWFhZKQkBDuaVSJlStXajVTI9eOHTtqtVq1aoViSo5RUFAg8fHx4Z4GDNyS4UOHDvkcN2zYUBtjahZ50003BXUe/r+irTZdtzsybE9uya8Vpj9/jh07ptUeeughrfbaa69ZeowePXr4HM+bN08bk5KSYulcdkJ+7ctOGb7gggu02jfffKPVunTpotVmz57tc5yWlqaNqYq/hWvXru1zXFxcHPLHrApk2J7slN9gMq2jzz33nFY7ceKEVrOa85MnT2q12NhYS/d1Giv55Z08AAAAAAAALsAmDwAAAAAAgAtUeJPnk08+kVtuuUVSUlIkIiJCli5d6vN1pZQ8/vjj0rhxY6lZs6ZkZmYa35oJoOqRX8DZyDDgXOQXcDYyDKeo8CZPcXGxdOjQQWbMmGH8+tSpU+XFF1+UmTNnyvr166V27drSs2dP4+fkAFQt8gs4GxkGnIv8As5GhuEUlWq8HBERIUuWLJE+ffqIyE+7lykpKTJhwgRvg6WCggJJSkqSOXPmyODBg897Trc2nDJ9mydPnqzVnnzySa22Zs0ardatW7fgTMyhaBhXeaHIr4h7MmzlV2ObNm202tdffx3wY5oasB44cCDg89kZGa481mDrPvnkE61mWkeD3dj83nvv9Tl+/fXXtTHjxo3Tajk5OUGdR7CR38qz6xp8Zj5n+L9ToSJM6+icOXO0Wp06dbRa//79fY5Nr7eioiKtZpd1tEGDBlrt6NGjVT6PsyHDlccabJ3pd8HBgwe1mtULEZjOZ2qy3Lp1a5/jrVu3Wjq/3VV54+Vdu3ZJbm6uZGZmemsJCQnSpUsXWbt2rfE+JSUlUlhY6HMDUPUCya8IGQbsgjUYcC7WYMDZWINhJ0Hd5MnNzRURkaSkJJ96UlKS92v+srOzJSEhwXtr1qxZMKcEwKJA8itChgG7YA0GnIs1GHA21mDYSdivrjVx4kQpKCjw3vbt2xfuKQGoADIMOBf5BZyNDAPORX4RKjWCebLk5GQREcnLy5PGjRt763l5edKxY0fjfTwej3g8nmBOwxbuvPPO844x9d957bXXtNr9998flDlVVvv27bWaWz7biMDyK+KODHfp0iWg+1Wm/46JW/vvoGqwBv8sMTHR59hqHzvT5/wr06fnX//613nHPPvss1qtZcuWWm3MmDEBzwP2Z5c1ONAePHXr1rU0ztRzo2fPnlqtQ4cOPsem/jsmwV5He/Xq5XNs6qtj6p153333aTXT3/hvvvmmVvPv5SWi9wDcsWOHPlmEFWvw2R06dEirWe2/M2LECEvjSkpKtNqQIUN8jn/7299aOlewPfbYYz7HTz/9dMgfM6jv5ElLS5Pk5GRZvny5t1ZYWCjr16+XjIyMYD4UgCAjv4CzkWHAucgv4GxkGHZS4XfyHDt2TL799lvv8a5du2Tz5s1Sv359SU1NlbFjx8rTTz8trVu3lrS0NJk0aZKkpKRo3foBVD3yCzgbGQaci/wCzkaG4RQV3uTZuHGjXH311d7j8ePHi4jI0KFDZc6cOfKb3/xGiouLZcSIEZKfny9du3aVjz76yHhZMwBVi/wCzkaGAeciv4CzkWE4RYU3eXr06GH8zPoZERERMmXKFJkyZUqlJgYg+Mgv4GxkGHAu8gs4GxmGU0Soc71Sw6CwsFASEhLCPY1Ke/31132OTQ3j+vXrp9U6deqk1UxN3qq7goICiY+PD/c0YODEDAe72WqgTM0nP/roI5/jcMwrFMiwPTkxvyb+l6v1v6Tt2Vx33XVabdmyZVrttttu02qDBg3Sav5NYEeOHKmN6d27t1Z7//33zznPcCO/9hWuDP/3v//VaqYLdpiYLjBialIcKFM2TY2iZ86cqdX8m8P26NFDG/PLd3acYerBYvX7YRLstZ8M25Nb1mD/hsePPPKINqZdu3YBn9/0d7upubN/bho1ahTwY9qJlfyG/RLqAAAAAAAAqDw2eQAAAAAAAFyATR4AAAAAAAAXYJMHAAAAAADABWi8HCL+zZAKCgos3c/OTVVNjeVWrlwZtPPfdNNNWu2vf/2rcSwN4+zLiRnu1auXVmvRooXP8YsvvhjUxwz0V+/GjRu1WufOnS3d17+BpIjeGLaqkGF7cmJ+TaKionyOT58+rY354IMPtJrpd4HJq6++qtVMTZX9c27nNb4iyK99hSvDVte0gQMHarV3331XqwWalb59+2q1tm3barWuXbtqtePHj2u11NRUn+P09HRtzPLly7Xatddeq9VMmYmM1P9/+9y5c7XazTff7HP8q1/9ShuzefNmrXY2ZNie3LIG+/8+6N+/vzbG9O++u+++W6uVlJRoNf81XkSkvLxcq8XExJxznqFw+eWXa7V169YF9TFovAwAAAAAAFBNsMkDAAAAAADgAmzyAAAAAAAAuACbPAAAAAAAAC5A4+VzqFu3rlbLz8+3dF//b6vpXG+99ZZW69Onj6XzV3c0jLMvO2XYqrvuukur/elPf/I5rkzDVNOvWdP3yNSgPdSNWuvUqaPVjh07FtLHFCHDduXE/FpRXFys1UwNy7/88kut9sQTT1iqmTz99NM+x5dddpk25oYbbrB0Ljshv/Zl98bLVrVp08bn2LQ+mv4mv/XWW7XavHnztJppbZ0yZYpWmzBhgs9xrVq1LJ0r1P+8quzfBmTYntyyBp84ccLnODY21tL9TBdJWLBggVbzb4guInLVVVdpNbdc7MAfjZcBAAAAAACqCTZ5AAAAAAAAXIBNHgAAAAAAABdgkwcAAAAAAMAFaoR7AnZmtcmyyeOPP37ec7m1GRRgF/6NG0VEduzYodVmz56t1Xbt2nXe819xxRVa7d///reluZmaSH7xxRdazb95Y7B/b1RFk2Ug3GrXrm1pnOkiCaas9urVS6tdeumlWm3SpEk+x3/84x8tzQOoTkzrmv/f0aamyCbz58/Xav/617+0mqkxsimfkydP9jl+/vnntTFNmzbValbX6iVLlmi1vXv3arUxY8b4HHfp0kUbs379ekuPCYRazZo1g3au48ePWzr/k08+GbTHdAPeyQMAAAAAAOACbPIAAAAAAAC4AJs8AAAAAAAALsAmDwAAAAAAgAvQeDlEVq5c6XN8/fXXa2O6d++u1VavXh2yOYmIjBgxQqu9/vrrIX1MVE/R0dE+jQdPnTpV5XMwNVm2atWqVT7HpmaLEyZM0GqmZoumBo8LFizQaoMHD67ADAEEm6nJsompybIVDz74YED3A+zuxx9/1Gr16tWzdF/TGmmlcfELL7yg1caPH2/pMU3N2E0NXq0w/T7Yv3+/Vvu///s/rdanTx+tNmfOnPM+Jk2W8dxzz2m1hx9+OAwzCS1Tk2XThUpee+21qpiOY/BOHgAAAAAAABdgkwcAAAAAAMAF2OQBAAAAAABwATZ5AAAAAAAAXIDGyyHSpUsXn2NT09aq8Ktf/crn+D//+U9Y5tG1a1ef4zVr1oRlHqg6paWlVfp40dHRIZ3DQw89ZKlmYmog+fnnnwd03x49emhj/JtEi4iMGjVKq7388suWHhOorj777DOttnz5cq3Wv39/rVZeXh6SOZ3RtGlTrWZq7gqEQ8eOHbXanj17LN3XdGEG/0bOdevWDWRaImLOScuWLbXaPffco9X8m6Wbxrz55pta7Y9//KNW+/Wvf63VTL9zPvjgA602bNgwrYbqzY1Nltu3b29pnClfBw8eDPZ0HI138gAAAAAAALgAmzwAAAAAAAAuwCYPAAAAAACAC0QopVS4J/FLhYWFkpCQEO5pVJr/t3XMmDHamFq1amm1kSNHarUTJ05otUGDBmm1gQMHarVHH33U59jUG8SJCgoKJD4+PtzTgEFFMpySkqLVDhw4EOwp2ZLVX71uyaw/MmxPblmDrQj2nz9uzaoJ+bWvimS4Rg29Nefp06eDNhdTxo4fP67VTH8P+zP1nrvooou0WlJSkrXJWfTYY4/5HD/99NNBPb/Jp59+qtXS09OD+hhk2J6q0xpsEuy/jYcOHepz/NZbb1V4TnZkJb+8kwcAAAAAAMAF2OQBAAAAAABwATZ5AAAAAAAAXIBNHgAAAAAAABfQO64hKPwbQn3xxRfamL1792q15s2bB/yYmzdv1molJSU+x6amtpGR+l5fcnJywPMArApmk+VLL71Uq3322WdBO3+wmRordu7cOQwzAaon03q7Z88erTZ79mytdvfdd4dkTkBVCmaTZZP3339fq1177bWW7uv/d3SwG6WbLojSv39/rWal0fJLL72k1UaPHh3YxERk27ZtAd0vKipKq5WVlQU8DyCUPvjgA6328MMPa7X//Oc/AT+GWxotB4J38gAAAAAAALgAmzwAAAAAAAAuUKFNnuzsbOncubPExcVJo0aNpE+fPrJjxw6fMSdPnpSsrCxp0KCB1KlTR/r16yd5eXlBnTSAwJBhwLnIL+BsZBhwLvILJ6nQJs/q1aslKytL1q1bJ8uWLZPS0lK57rrrpLi42Dtm3Lhx8uGHH8qiRYtk9erVcuDAAbn11luDPnEAFUeGAeciv4CzkWHAucgvnCRCVaKT2eHDh6VRo0ayevVqueqqq6SgoEAaNmwo8+bN8zYv2759u1x00UWydu1aufzyy897zsLCQklISAh0So5i+taPHz9eq02fPt3S+a6//nqt1qZNG5/jnJwcbcybb76p1e69915LjxkuBQUFEh8fH+5pOB4ZDp9///vfWs2/0aSIyBVXXFEV06lyZLjyyK91K1as0GpXX321Vps/f75Wu/322y2d75prrglwds5DfoOjOmb4jjvu0GrvvPOOVvN/rmvXrtXGzJs3T6uZ8vq3v/1Nq914443nnOfZmJqzm5q4m35HmJrKxsTEaLV169YFNLfGjRtrtYMHDxrHkuHKq475DSbTv4NfeOEFrfbQQw9VxXQcxUp+K9WTp6CgQERE6tevLyIimzZtktLSUsnMzPSOadu2raSmphp/OQMILzIMOBf5BZyNDAPORX5hZwFfQr28vFzGjh0rV155pbRv315ERHJzcyUmJkbq1q3rMzYpKUlyc3ON5ykpKfG5zHdhYWGgUwJQAWQYcC7yCzgbGQaci/zC7gJ+J09WVpZs3bpVFixYUKkJZGdnS0JCgvfWrFmzSp0PgDVkGHAu8gs4GxkGnIv8wu4C2uQZNWqU/OUvf5GVK1dK06ZNvfXk5GQ5deqU5Ofn+4zPy8uT5ORk47kmTpwoBQUF3tu+ffsCmRKACiDDgHORX8DZyDDgXOQXTlChj2sppWT06NGyZMkSWbVqlaSlpfl8vVOnThIdHS3Lly+Xfv36iYjIjh07ZO/evZKRkWE8p8fjEY/HE+D0nW3KlCla7e6779ZqpsbLzz//vFbbtWuXVvNvtPzb3/5WGzN16tRzTRMuQobD46mnntJqpobKiYmJVTEdOBT5DZypybIpb2PHjrV0PqtNlv0vYvDGG29Yuh/ciQybmyyb/Otf//I5XrlypTamSZMmls6VlZWl1ZYvX27pfP5NcJcsWaKNadGihaV5hFq9evW02tkaL6PinJjfX25CnbF///6QPV5lnThxQquZMte3b9+qmI6jVWiTJysrS+bNmyfvv/++xMXFeT9fmJCQIDVr1pSEhAQZPny4jB8/XurXry/x8fEyevRoycjIsNRRHEBokWHAucgv4GxkGHAu8gsnqdAmz6uvvioiIj169PCpz549W4YNGyYiP73rJDIyUvr16yclJSXSs2dPeeWVV4IyWQCVQ4YB5yK/gLORYcC5yC+cpMIf1zqf2NhYmTFjhsyYMSPgSQEIDTIMOBf5BZyNDAPORX7hJAFfXQsAAAAAAAD2UaF38iC4Jk+erNV++OEHrbZixQqt9vHHH1u6b0pKis9xly5dKjLFkImPj9dqhYWFYZgJEHrfffedpXHFxcUhngngbFFRUVqtrKxMq/n/H1f/t9eLiLRq1UqrTZo0KfDJGdBoGQhMdHR0SM9vyr8VN954Y5BnEjzbtm0L9xRgM3ZpsjxmzBhL4z788EOtFsx1OTY2VqudPHkyaOe3E97JAwAAAAAA4AJs8gAAAAAAALgAmzwAAAAAAAAuwCYPAAAAAACAC9B42Wb++Mc/arVjx45ptfXr12u1rVu3nvf8S5cuDWhewUaTZVQnWVlZlsa5tfkbECxt2rTRalaajb777rtabffu3VrNLhcnAAAgFFq2bKnVrF4gxKpnnnnG5/i3v/2tNmb8+PFabcOGDUGdR3Jyss9xbm5uUM9vZ7yTBwAAAAAAwAXY5AEAAAAAAHABNnkAAAAAAABcgE0eAAAAAAAAF6DxsgPMmjUr3FMAUAmmBq+dOnWq+okAQRQZqf9/ovLy8pA+ppUmyyIie/fu9TlOTU3VxpiaOAMA4GbBbrJs4t9oed26ddqYRYsWhXweTmq0/MEHH2i1Xr16BXw+3skDAAAAAADgAmzyAAAAAAAAuACbPAAAAAAAAC5ATx5Io0aNtNqhQ4fCMBPAnfr166fVcnJyqn4iBrfddptWmz9/fhhmAqcJdf+dyvDvg2Waa35+ftVMBkCVGThwoFZ79913Q/qY48aN02rTp08P6WMCdtGhQ4fzjsnIyKiCmQRPOHoOVqb/jgnv5AEAAAAAAHABNnkAAAAAAABcgE0eAAAAAAAAF2CTBwAAAAAAwAUilFIq3JP4pcLCQklISAj3NGBzBQUFEh8fH+5pwKAiGe7YsaNW27x5c3AnBFsiw/bEGoxfqlOnjs+xUkqKi4vJr43ZPcMjRozQaq+//noYZlK9kWF7snt+TZo3b67V9uzZE4aZ2JfH4/E5LikpqdT5rOSXd/IAAAAAAAC4AJs8AAAAAAAALsAmDwAAAAAAgAuwyQMAAAAAAOACNcI9AQSPqQFTYWFhGGYCWEOTZQBu4cZG8seOHQv3FOAyNFkG3IUmy+dX2UbLgeCdPAAAAAAAAC7AJg8AAAAAAIALsMkDAAAAAADgArbryaOUCvcUHKs6fe+q03N1Gn42sILXiT3xcwlcWVlZuKdQZXid2Bc/G1jB68Se+LnACiuvE9tt8hQVFYV7Co5Vnb53RUVFkpCQEO5pwKA6vQ4RODJsT+Q3cP/973/DPYUqQ37tiwzDCjJsT+QXVljJb4Sy2ZZheXm5HDhwQOLi4qSoqEiaNWsm+/btM145yu4KCwsdPX8R+z0HpZQUFRVJSkqKREbyaUM7OpNhpZSkpqba5rUTCLu9/ivKjvMnw/bGGmwvdnsO5Nf+WIPtw47zJ8P2xhpsL3Z7DhXJr+3eyRMZGSlNmzYVEZGIiAgR+enS4Hb4xgbK6fMXsddz4P882NuZDBcWFoqIvV47gXL6c7Db/MmwfbEG25OdngP5tTfWYPux2/zJsH2xBtuTnZ6D1fyyhQsAAAAAAOACbPIAAAAAAAC4gK03eTwej0yePFk8Hk+4pxIQp89fpGqew+7duyUiIkLmzJkTssdA1eP1H37kF5XB6z/8yDACxes//Kpq/mTYnXj9h5+j12DlYLNnz1Yi4r1FRUWplJQUNXToULV///5wTy+oZsyYoWbPnu3KOezatUuJSNifH6oW+XXHHMhv9UWG3TEHMlx9kWF3zIEMV0/k1x1zCFV+bdd4ORBTpkyRtLQ0OXnypKxbt07mzJkja9aska1bt0psbGy4pxcUr7zyiiQmJsqwYcOq9RzgPuS3+swB7kSGq88c4E5kuPrMAe5DfqvPHCrCFZs8N9xwg1x22WUiInLPPfdIYmKiPPvss/LBBx/IwIEDwzy7qldcXCy1a9cO9zQAS8ivL/ILpyHDvsgwnIYM+yLDcBLy64v8/sTWPXkC1a1bNxER2blzp7e2fft26d+/v9SvX19iY2Plsssukw8++EC7b35+vowbN05atGghHo9HmjZtKnfeeaccOXLEO+bQoUMyfPhwSUpKktjYWOnQoYO89dZbPuc58/m6559/Xl5//XVp1aqVeDwe6dy5s3z66ac+Y3Nzc+Wuu+6Spk2bisfjkcaNG0vv3r1l9+7dIiLSokUL+fLLL2X16tUSEREhERER0qNHDxERmTNnjkRERMjq1atl5MiR0qhRI++l94YNGyYtWrTQnuMTTzzhvSzfL82dO1fS09OlVq1aUq9ePbnqqqvkH//4x3nncOb7NnbsWGnWrJl4PB654IIL5Nlnn5Xy8nLt+zts2DBJSEiQunXrytChQyU/P1+bC6ov8kt+4WxkmAzD2cgwGYZzkV/yK+KSd/L4O/OiqFevnoiIfPnll3LllVdKkyZN5JFHHpHatWvLu+++K3369JH33ntP+vbtKyIix44dk27duslXX30ld999t1x66aVy5MgR+eCDD2T//v2SmJgoJ06ckB49esi3334ro0aNkrS0NFm0aJEMGzZM8vPz5cEHH/SZy7x586SoqEjuu+8+iYiIkKlTp8qtt94q3333nURHR4uISL9+/eTLL7+U0aNHS4sWLeTQoUOybNky2bt3r7Ro0UJycnJk9OjRUqdOHfnd734nIiJJSUk+jzNy5Ehp2LChPP7441JcXFzh79mTTz4pTzzxhFxxxRUyZcoUiYmJkfXr18uKFSvkuuuuO+ccjh8/Lt27d5fvv/9e7rvvPklNTZX//Oc/MnHiRDl48KDk5OSIiIhSSnr37i1r1qyR+++/Xy666CJZsmSJDB06tMLzhXuRX/ILZyPDZBjORobJMJyL/JLfMw9oSy+//LJq3ry58ng8Kj09Xa1fv14bc6bh1D//+U91+PBhtW/fPrV48WLVsGFD5fF41L59+5RSSl177bXqkksuUSdPnvTet7y8XF1xxRWqdevW3trjjz+uRET9+c9/1h6rvLxcKaVUTk6OEhE1d+5c79eWL1+u6tWrpyIiIpSIqCVLlnibKDVo0EAdPXpUTZo0SSUnJ6vo6GglIuq1115TSin1448/KhFRzz333Dm/H+3atVPdu3c/6/ega9eu6vTp0z5fGzp0qGrevLl2n8mTJ6tf/ugnTJjgbdiVmJioevfurbZv3+7zvE+cOKHq16+vatSooWrXrq1uvfVWlZubq5RS6qmnnlK1a9dWX3/9tc/jPPLIIyoqKkrt3btXKaXU0qVLlYioqVOnesecPn1adevWjYZxLnS+DNslv6dOnVLt2rVTUVFRKikpyZvPM/n94YcfVHl5uZo0aZKqW7euEhHVoUMH9fXXX9siv998842KiIhQdevWVbVr11YNGzb0ZvjM81ZKqYsvvlilpKSo+vXr+2SY/MKENdgXazCchgz7IsNwEvLri/xWnC0/rrVw4UIZP368TJ48WT777DPp0KGD9OzZUw4dOmQcn5mZKQ0bNpRmzZpJ//79pXbt2vLBBx9I06ZN5YcffpAVK1bIwIEDpaioSI4cOSJHjhyRo0ePSs+ePeWbb76R77//XkRE3nvvPenQoYN3R/OXzryt629/+5skJyfLbbfd5v1aSUmJdO/eXZRS2v0GDRokb7zxhrz44osyc+ZMWbFihYiITJw4UU6ePCk1a9aUmJgYWbVqlfz4448Bf8/uvfdeiYqKCui+H374oYj89H3/5z//KaWlpXLddddJcXGx93mPGzdOCgsLpV27drJ69Wo5cOCA3HrrrSIismjRIunWrZvUq1fP+/09cuSIZGZmSllZmXzyySci8tP3rkaNGvLAAw94HzsqKkpGjx4d8POGPVUkw+HOb3R0tNx8881SVlYmw4cP97nfoEGDpF69ejJ16lR58cUX5eWXXxYRkbKyMunZs6dERESEPb9Lly4VpZSMGzdO1q9fL8uWLfNm+Pjx495xBw8elKNHj8qiRYt8Mkx+4Y81uOJYg2EnZLjiyDDsgvxWHPk1COqWUZCkp6errKws73FZWZlKSUlR2dnZPuPO7N7NmDFDLVu2TC1evFjdeOONqk6dOmrVqlVKKaXWr1/vc3k50+2zzz5TSikVGxur7rjjjnPOrU2bNqpbt25affPmzd7z/XIHMzs7WyUnJ/vsUMr/3y2cP3++Ukqp6dOnq8jISBUdHa26deumnn32WXXw4EGf859vB/OTTz7RvmZ1B/P+++9XkZGRqqSkRCml1KFDh5SIqNWrVyullMrPz1fR0dGqWbNm3jl89dVXSkTU2rVrVc2aNc/5/Z02bZpSSqmePXuqZs2aafP54osv+D8QLmMlw3bM78svv+zzTp5nnnlGlZeX+2RYRNQjjzyiPB6Pmj9/vu3yq5Q5wyKiLr74Yu+YMxn2eDzkFz5Yg1mD4WxkmAzDucgv+Q0G2/XkOXXqlGzatEkmTpzorUVGRkpmZqasXbvWeJ/09HRvV/E+ffpI165d5fbbb5cdO3Z4Gx499NBD0rNnT+P9L7jggiA/i58VFBRIbm6uZGZm+tSbNGkia9eulcGDB8vYsWPllltukaVLl8rHH38skyZNkuzsbFmxYoX86le/svQ4NWvW1GqmplIiP70L4XxzFhGpX7++iIhs2rRJSktLfTqVt23bVlJTU2Xt2rVSXl4u//u//yu/+c1vjOe78MILLT0HuENFM2zn/EZFRcmuXbu0DHs8HunSpYusXbtW/vjHP9oqvyLmDIv8/PlskZ8zfODAAfILL9bg8GeYNRiVQYbJMJyL/JLfYLHdJs+RI0ekrKxMa6iUlJQk27dvP+/9o6KiJDs7W66++mp5+eWX5e677xaRnz6S4f8C89eqVSvZunXrOcc0b95ctmzZIuXl5RIZ+fOn3c42t6KiIu/8f6lOnTqSm5vr89gTJkyQCRMmyDfffCMdO3aUF154QebOnSsiZ3+hnku9evWMHbv37Nnjc9yqVSspLy+Xbdu2yf/8z//I2LFj5corr5T27duLyE9dz2NiYqRGDd+XS1JSkuTm5kqrVq3k2LFj5/3+Nm/eXJYvXy7Hjh2TOnXqeOs7duyo8HODfVUmw+HOb/PmzbX7nMmp6fmc+Zpd8tuxY0cpLy83ZjgiIsKY4eLiYvILL9Zg1mA4Gxkmw3Au8kt+g8WWPXkqq0ePHpKeni45OTkSHx8vPXr0kNdee00OHjyojT18+LD3v/v16ydffPGFLFmyRBun/v/nDG+88UbJzc2VhQsXer92+vRpeemll3x+YFYdP35cTp486VNr1aqVxMXFSUlJibdWu3btCl9irVWrVlJQUCBbtmzx1g4ePKg9vz59+khkZKRMmTJFRo4cKVu3bpUFCxaIiPh8vvJscxg4cKCsXbtWPv74Y+1r+fn5cvr0aRH56Xt3+vRpefXVV71fLysrk5deeqlCzwvuFs78du/evUJzPX36tK3yW15eLllZWd4MK7/PR5vm0LZtW/KLoGIN/vk8rMFwIjL883nIMJyG/P58nuqcX9u9kycxMVGioqIkLy/Pp56XlyfJycmWz/Pwww/LgAEDZM6cOTJjxgzp2rWrXHLJJXLvvfdKy5YtJS8vT9auXSv79++XL774wnufxYsXy4ABA+Tuu++WTp06yQ8//CAffPCBzJw5Uzp06CAjRoyQ1157TYYNGyabNm2SFi1ayOLFi+Xf//635OTkyNixY33mERcX551/48aNvfVjx45JcnKyfP3113LttdfKwIED5eKLL5YaNWrIkiVLJC8vTwYPHuwd36lTJ3n11Vfl6aeflgsuuEAaNWok11xzzTm/B4MHD5bf/va30rdvXxkzZowcP35cXn31Vbnwwgvls88+84674IIL5He/+5089dRTEhMTIw899JAsXbpUPv30U0lJSZH//d//lVOnTkn79u3lT3/6k3cOe/bskeTkZLnvvvvkgw8+kJtvvlmGDRsmnTp1kuLiYvnvf/8rixcvlt27d0tiYqLccsstcuWVV8ojjzwiu3fvlosvvlj+/Oc/e98WB3cIRobDld8zef2lM3P2z3BeXp40adJEmjRpYpv8NmnSRE6cOCHjxo2T3/3ud5KSkiLZ2dmSnJwsSinZsmWLzxzy8vJk5MiRcuLECfILEWENDneGWYNRWWSYDMO5yC/5DZqgdvgJkvT0dDVq1CjvcVlZmWrSpMlZG059+umn2jnKyspUq1atVKtWrdTp06fVzp071Z133um9fFuTJk3UzTffrBYvXuxzv6NHj6pRo0apJk2aqJiYGNW0aVM1dOhQdeTIEe+YvLw8ddddd6nExEQVExOjLrnkEm+zJPFrODV16lSVnJysnn/+ee/95RcNp44cOaKysrJU27ZtVe3atVVCQoLq0qWLevfdd33mlZubq2666SYVFxenRMTb+Olc3wOllPrHP/6h2rdvr2JiYlSbNm3U3LlztYZT5eXlKisrS9WtW1ddfPHFyuPxqHr16qnu3burZcuWeRtOvfnmmz5zkP/fcEoppYqKitTEiRPVBRdcoGJiYlRiYqK64oor1PPPP69OnTrl8/0dMmSIio+PVwkJCWrIkCHq888/p2Gcy1jJsB3zq5Tyabz83HPPeRsvn8mw/KLx8uuvvx72/Cr1U4avueYaFR0drWJiYnzyq9RPTeNq1KihLr30Uu8cOnfu7M0w+cUvsQazBsPZyDAZhnORX/IbDLbc5FmwYIHyeDxqzpw5atu2bWrEiBGqbt263uvR201RUZH6/PPPvT+kadOmqc8//1zt2bNHKaXUM888o+rWravef/99tWXLFtW7d2+VlpamTpw4EeaZ/+SBBx5QCQkJatWqVergwYPe2/Hjx71j7r//fpWamqpWrFihNm7cqDIyMlRGRkYYZw07I8NViwwjmMhv1SK/CDYyXLXIMIKJ/FYtt+bXlps8Sin10ksvqdTUVBUTE6PS09PVunXrwj2ls1q5cqXxkmlDhw5VSv20Qzhp0iSVlJSkPB6Puvbaa9WOHTvCO+lfMM3df0fxxIkTauTIkapevXqqVq1aqm/fvtrl7YBfIsNVhwwj2Mhv1SG/CAUyXHXIMIKN/FYdt+Y3Qim/zpwAAAAAAABwHFdeXQsAAAAAAKC6YZMHAAAAAADABdjkAQAAAAAAcIGQbfLMmDFDWrRoIbGxsdKlSxfZsGFDqB4KQJCRX8DZyDDgXOQXcDYyjHALSePlhQsXyp133ikzZ86ULl26SE5OjixatEh27NghjRo1Oud9y8vL5cCBAxIXFycRERHBnhocTiklRUVFkpKSIpGRvBEtFCqTXxEyjHMjw6HHGoxQIb+hxxqMUCLDoccajFCpUH5Dccmu9PR0lZWV5T0uKytTKSkpKjs7+7z33bdv31kvZcaN25nbvn37QvHShapcfpUiw9ys3chw6LAGcwv1jfyGDmswt6q4keHQYQ3mFuqblfwGfQv31KlTsmnTJsnMzPTWIiMjJTMzU9auXXve+8fFxQV7SnAhXiehUdn8ivCzgTW8TkKDNRhVgddJaLAGo6rwOgkN1mBUBSuvkxrBftAjR45IWVmZJCUl+dSTkpJk+/bt2viSkhIpKSnxHhcVFQV7SnAh3sIYGhXNrwgZRmDIcGiwBqMqkN/QYA1GVSHDocEajKpgJb9h/zBmdna2JCQkeG/NmjUL95QAVAAZBpyL/ALORoYB5yK/CJWgb/IkJiZKVFSU5OXl+dTz8vIkOTlZGz9x4kQpKCjw3vbt2xfsKQGwqKL5FSHDgJ2wBgPOxRoMOBtrMOwi6Js8MTEx0qlTJ1m+fLm3Vl5eLsuXL5eMjAxtvMfjkfj4eJ8bgPCoaH5FyDBgJ6zBgHOxBp9dVFSUpVtERIR2M40DQoE1GHYR9J48IiLjx4+XoUOHymWXXSbp6emSk5MjxcXFctddd4Xi4QAEEfkFnI0MA85FfgFnI8Owg5Bs8gwaNEgOHz4sjz/+uOTm5krHjh3lo48+0ppQAbAf8gs4GxkGnIv8As5GhmEHEUopFe5J/FJhYaEkJCSEexqwuYKCAt7SaFNkGFaQYXsiv7CC/NqXWzNs9SNW5eXlWi0yUu9OUVZWVuk5ORkZtie35hfBZSW/Yb+6FgAAAAAAACovJB/XAgAAAIBARERE+BxPmTJFG3P11VdrtdWrV2u1Z599VqsVFBRoNZt9uAEAAsY7eQAAAAAAAFyATR4AAAAAAAAXYJMHAAAAAADABdjkAQAAAAAAcAEaLztUdHS0VqtXr55Wi42N9Tk2XTLy8OHDWu3UqVOVmB0AAOHj37SVhqqAPZguhZ6cnKzVXnrpJZ/ja665RhtTs2ZNrdauXTuttmHDBq22dOnSc00TAByNd/IAAAAAAAC4AJs8AAAAAAAALsAmDwAAAAAAgAvQk+f/8//8/tmE+nP9pnk0aNBAqw0fPlyr9erVS6vVqVPH5/iTTz7Rxjz//PNabc+ePeecJwAAdkUPnuCgtxGCzfQamj59ula78cYbfY5r1ND/yVJSUqLVTp8+rdWaNGlSkSmGnZV/k5BFwP0qswbzTh4AAAAAAAAXYJMHAAAAAADABdjkAQAAAAAAcAE2eQAAAAAAAFyAxsv/n9VGRqZmaMFsfhYVFaXVMjMztdrYsWO1mqlBs39TOlPjuhdeeKECMwRwLpGR+t55TEyMVjNl/dSpU1rNv4kkzRZRXVi9IIJJOHJiJefl5eXaGFPzWLvg9w2CLSkpSatdc801Wi06Otrn2LS2ejwerWbKU2lpqVYL9d/zlWGXeQB2YMpqSkqKVktPT9dq+fn5PscbN27Uxhw7dkyr2SWDlZkH7+QBAAAAAABwATZ5AAAAAAAAXIBNHgAAAAAAABdgkwcAAAAAAMAFaLwcRqZGUk2bNtVqDz74oFarX7++VvNvLiWiN67bv3+/NsbUpM7ODemAcDBlwtTsfMCAAVrtzjvv1Gp16tTRav/+97+12sKFC32ON2zYoI05fvy4ViOvcDrTazjUa5Pp/KaGyl26dNFqL774olZr2LChz/GaNWu0Mffff79W+/HHH885T8AJTHm65ZZbLN3Xv1myKYemnKxbt06rLV++XKuZLkTif6EDEf33Szh+LwHVRWxsrFa75557tFpWVpZWS05O1mp79uzxOe7fv782pri4WKu5Ib+8kwcAAAAAAMAF2OQBAAAAAABwATZ5AAAAAAAAXIBNHgAAAAAAABeg8XIFBbMRk6l58ksvvaTV2rVrp9VMTaK2bdum1dauXetz/OWXX2pjIiPZ6wP8+efiwgsv1Mbk5ORotQ4dOmi1WrVqabWysjKtduutt2q1zp07+xwPHz5cG/Pf//7X0vkrw7+xpBua0sF5An3dmRqj1q1bV6tdf/31Wm306NFa7ZJLLtFqNWvW1GpRUVE+x3369NHGLFu2TKv96U9/0mrl5eVaDbAzU+4uu+wyreZ/kRARvdHyyZMntTEbN27UauPGjdNqhw4d0mq1a9fWaqdOndJqpsf1Z/X3EusmqitTo/PmzZtrtVmzZmm1Tp06aTWrf1f7Z7o6XaiEf90DAAAAAAC4AJs8AAAAAAAALsAmDwAAAAAAgAuwyQMAAAAAAOACNF6uIrGxsVpt0qRJWq1Hjx5azdQQasuWLVpt/PjxWu3AgQPnPdexY8e0WmWYGu3516w2kKTZK6qC6TV7wQUX+Bz/3//9nzamSZMmWm3Xrl1abenSpVqtqKhIq5may5WWlvocm5rNmZqnB7vxMtmDkzVt2lSrmRoep6amajVTM9b8/Hyt5r/eiogkJyf7HJtydNNNN2m1hQsXajXTWk0uYWf+r38Rkb59+2q1uLg4rXb69Gmf4/3792tjHnroIa323XffaTXT35ymRrAej+e89zX9vWA6l+kxTesyGUZ1YLqIkOlvY9PvDP/fBSIihYWFWs30O+LZZ5/1OT5y5Ig2JtgZNP2OCEfOeScPAAAAAACAC7DJAwAAAAAA4AJs8gAAAAAAALgAmzwAAAAAAAAuQOPlEPFvutS8eXNtTK9evbRazZo1tdrBgwe12muvvabVtm/frtX8m7aaGj+ZmsNZbRBlai4VTDSkQ1WoW7euVps/f77Psalp3JdffqnVHnjgAUvjoqKitNr69eu1mn8DaFNz12A3WTahCTqcxL8R6qOPPqqNSUtLs3QuUy4ffPBBrWZaS/3X+XHjxmljmjVrptXq1Kmj1SpzkQTyi1Az/T3o3/RUxLzemvg3Vh09erQ2xvR3r9ULe5iauVr5e9jKxUVEzM+zuLhYq5nWb/+/3U3zAOysdu3aPscvv/yyNiYpKUmr5ebmarXnn39eq5n+Fjb9nW66SEIwWf19EOgFiCqDd/IAAAAAAAC4AJs8AAAAAAAALlDhTZ5PPvlEbrnlFklJSZGIiAjtGvdKKXn88celcePGUrNmTcnMzJRvvvkmWPMFUAnkF3A2Mgw4F/kFnI0MwykqvMlTXFwsHTp0kBkzZhi/PnXqVHnxxRdl5syZsn79eqldu7b07NlTTp48WenJAqgc8gs4GxkGnIv8As5GhuEUFW68fMMNN8gNN9xg/JpSSnJycuSxxx6T3r17i4jI22+/LUlJSbJ06VIZPHhw5WbrILVq1fI5fvPNN7UxjRs31monTpzQahs3btRq//znPy3d15+pGVSwm7mZHqMqGkzh/MivSGSkvrd9xx13aLXWrVv7HJ86dUob89BDD2m1LVu2aDVTxkxNH01N1i+++GKfY4/Ho40xPafKZM50Ppo+2gMZtsa/YfmAAQO0MaY109TMMSsrS6vt2rVLq/k3ezbVYmJitDH169fXavHx8VrN1JASzuLm/CYnJ2u1W2+9VauZ1ibTmuOfxU8++UQbU5mLDlj9e9h/bv4NZUX0vxdERG6//XattnXrVq32n//8R6vt3r1bq5n+BkHVc3OGg+nXv/61z3HHjh21MRs2bNBqjz32mFYz5SYhIUGrde/eXav5X/zgiy++0MYcPXpUq1n9m9f0u8t/D0BE5Pjx45bOF0xB7cmza9cuyc3NlczMTG8tISFBunTpImvXrjXep6SkRAoLC31uAKpeIPkVIcOAXbAGA87FGgw4G2sw7CSomzxn/i+T/yXRkpKSzvp/oLKzsyUhIcF7M11KFEDoBZJfETIM2AVrMOBcrMGAs7EGw07CfnWtiRMnSkFBgfe2b9++cE8JQAWQYcC5yC/gbGQYcC7yi1CpcE+ecznzedy8vDyffjN5eXnGz+KJ/NRfwtRjwumaN2/uc9yhQwdtTGxsrFbLy8vTar///e+12o8//qjVrHx+sCr6atC7w5kCya+I8zIcHR2t1fr06aPVatas6XO8YMECbcy///1vrVaZz/G2adNGqw0fPtzn+Ntvv9XGVEXPK3Jtf6zBP2vfvr3Psek5RkVFabVVq1ZptYKCAq1mOl/Dhg212pAhQ3yO69Wrp41ZvXq1Vvv++++1WmUySH7tz+lr8IMPPqjV/NfRszH1m/HvZVlSUhLYxM7C9Dd4q1attJr/3wfXXnutNsb/nRsi5h5Fpr5d69at02qmdf7JJ5/0OTb9ewHhVV3XYNP877zzTp/j4uJibcxHH32k1b7++mutZsrN+PHjtZqpB9ihQ4d8jk2/kyqzPpr+/rZL/6ygvpMnLS1NkpOTZfny5d5aYWGhrF+/XjIyMoL5UACCjPwCzkaGAeciv4CzkWHYSYXfyXPs2DGfHeZdu3bJ5s2bpX79+pKamipjx46Vp59+Wlq3bi1paWkyadIkSUlJMf6fcgBVi/wCzkaGAeciv4CzkWE4RYU3eTZu3ChXX3219/jM26WGDh0qc+bMkd/85jdSXFwsI0aMkPz8fOnatat89NFHxrdFAqha5BdwNjIMOBf5BZyNDMMpKrzJ06NHj3N+di0iIkKmTJkiU6ZMqdTEAAQf+QWcjQwDzkV+AWcjw3CKoDZerq5MDVQHDRrkc2xqGmVqzPSPf/xDq3355ZdaraysrCJTDBnTL7qIiIgwzAQInCmf/pe7NDVeLi0ttXR+UyZatmyp1aZPn67V/LN++vRpS49ZGVXRyBkIFlO+fvl/WkXMGTdl6YorrtBqv/3tb7XaiRMntJrp7fitW7f2OfZvAiki8tJLL2k1U5NKwC5Mf/fefvvtWs1qQ1PTFYVmzZrlc2x1XTL9PqhVq5ZWGzNmjFYbOXKkVvNvoGw6v6lm+v1iGmdq5HzNNddoNf9m8ldddZU2BgiHBg0aaLULL7zQ59iUB9NFDbp166bVBg8erNWuv/56rWZ6t9TWrVt9jk1rcGWYfseZflf5X+ihKv4dH/ZLqAMAAAAAAKDy2OQBAAAAAABwATZ5AAAAAAAAXIBNHgAAAAAAABeg8XIQeDwerXbZZZedd8zmzZu12oQJE7TayZMntZrVZnb+TM3yTOeyen6rTZb9xwU6f6CyTK+9w4cPa7WDBw/6HO/cuVMbEx0drdVMzdQaNmyo1V5//XWt1qJFC63m36yO7MBJTGtEsF/DpqbKqampPsf+TQ9FzOuhKYMDBgzQaiUlJed9TBH9+Zt+j3z22WdajZzDzhITE7VavXr1tJopY6ampGvWrNFq/hmw2vA4ISFBq02bNk2r3XLLLVqtbt26Ws3/OZjmb6qZGs2a/j6oU6fOeR9TROTiiy/WaoAdtGvXTqvFx8f7HJsycs8992i1xo0bazXTGm9qpm76feD/t7bpokfBZvV3RKjxTh4AAAAAAAAXYJMHAAAAAADABdjkAQAAAAAAcAE2eQAAAAAAAFyAxstB0KBBA63WsmVLn2NT8+S33npLqxUVFWm1yjRBttLwuDINHk33tdqMGQgHU/OzefPmabWMjAyf44suukgbY2o+eemll2q1IUOGaLVWrVppNVMjuaNHj/ocFxQUaGNo0gq7srpGVOY1bGpm+sYbb/gcm/Jrap4cGxtr6fymBs2mcf5NHv/85z9rY44fP67VADtLSUnRaqYLEZiYcuL/N7OJqRlxzZo1tVq3bt20mmm9Nd3X1JS1tLTU5/jbb7/Vxnz//fdazdQA2tRA9oILLtBqpos1mJ4/UNVM67dpDdu/f7/Pce3atbUxpt8FpnFW/13pf8EUEZH169f7HFfF38um5xUO/MYAAAAAAABwATZ5AAAAAAAAXIBNHgAAAAAAABdgkwcAAAAAAMAFaLwcBB6PR6v98MMPPsdff/21Nmb79u1azdQQytSozWoDOv8mclYaQ1YWzZhhZ6bGy1999ZVW6969u8/xww8/rI0xva5TU1O1WlRUlFarU6eOVjNl3b8Z87Fjx7QxVdFIzkoTd8CKYDdjNmX6L3/5i8/xihUrtDGmZqzNmjXTasOGDdNqjRs31moxMTFazb8hq6nxsmn+gJ01atQo4Pua1sP27dtrtUsuucTn+LvvvtPG9OzZU6vddtttWi05OVmrHThwQKuZfuc8++yzPsf+jVzP5uKLL9ZqpqayOTk5Ws30O8H0Nz5Q1UwZ2bRpk1br0aOHz7Hp359paWla7ZFHHtFqV155pVYzXTjBlM0jR45oteqCd/IAAAAAAAC4AJs8AAAAAAAALsAmDwAAAAAAgAuwyQMAAAAAAOACNF4OgoKCAq32xRdf+Bx37txZGzNkyBCt1r9/f612+vRprWZq0GpqfPXtt9/6HG/btk0bk5eXp9WC3QiSJq2wC9Nre/fu3VrNv3Hrvn37tDFXXHGFpXOZGsSZGkaamln6N43zb8QsUrmmtVaRYYRSsF9f/jk3NSz/73//q9VMzSFbtGih1UwXP/jxxx+12vTp032ODx48qI0hW3CazZs3azWrfzdabbzeq1cvn+OtW7dqYyZMmKDVEhMTtVpRUZFWMzVeXrVqlVZbvny5z7Fp/qYLsERHR2u1e++919J9Tc2pg32RFCBYTp48qdVMfzP7M/37c/HixVotIyNDqxUXF2u1efPmaTXTml5d8E4eAAAAAAAAF2CTBwAAAAAAwAXY5AEAAAAAAHABNnkAAAAAAABcgMbLQWBqwNiyZUuf4+TkZG1M27ZttZqpcZ2paVRhYaFWa9Wq1XnP995772ljFi5cqNVMDSQBtzI1jVuzZo3P8X/+8x9tzKxZs7SaqSm6qRFkt27dtJop63v37vU5zs3N1cbQuBU4N1NjV1Nj1Pvuu0+rtWnTRquZ1n3/3xkiIkuXLvU5Li0tPdc0AUfwvyCAiLnR6oUXXqjVTNmpXbu2VhsxYsR57xcfH6/VTOuoaZzpd8JNN92k1bp37+5zfOjQIW1MamqqVjOty5dccolWM/0eMjF9zwG3ueqqq7RaXFycVjM1Yjc1Tg/2hYSchHfyAAAAAAAAuACbPAAAAAAAAC7AJg8AAAAAAIAL0JMnCIqKirTazp07fY5N/TdOnTql1Uyf4TX1xzl+/LhWi42N1WoNGzb0OR4+fLg2JiUlRav94Q9/0GqmviWAW1l5vZtyaGL6zL0p/yUlJVpt8+bNFZ4XAF+m9fHee+/Vavfcc49WM63Lu3bt0mqPPfaYVvPv30H/LLiBqc/Fm2++qdWefvpprRYVFWWp5t+Hw7SOmuZh6otnGteiRQutZur7479Wx8TEaGOsMs3N9G8I0zz++c9/Bvy4gB21bt1aq912221a7fTp01rt9ddf12oFBQXBmZhL8E4eAAAAAAAAF2CTBwAAAAAAwAXY5AEAAAAAAHABNnkAAAAAAABcgMbLQWBqlrps2TKf44yMDG2Mf1M5EZGtW7daquXm5mq122+/XavVq1fP57h+/framB49emi1P/7xj1qNhq9AYDwej1Zr2rSpVjM1n3z77bd9jk0NJAH48m+Oes0112hjHn744fPeT8R88YOxY8dqtW+++UarlZWVnWuagGu89NJLWi0pKUmrmZqbmxqjm9ZDf6YGxabm5qamzVbHRURE+Bybmif7jzmbY8eOabXDhw9rtT59+mi17du3W3oMwI5M2XrjjTe0Ws2aNbXa/v37tdp7772n1UpLSwOcnTvxTh4AAAAAAAAXYJMHAAAAAADABSq0yZOdnS2dO3eWuLg4adSokfTp00d27NjhM+bkyZOSlZUlDRo0kDp16ki/fv0kLy8vqJMGEBgyDDgX+QWcjQwDzkV+4SQV2uRZvXq1ZGVlybp162TZsmVSWloq1113nRQXF3vHjBs3Tj788ENZtGiRrF69Wg4cOCC33npr0CcOoOLIMOBc5BdwNjIMOBf5hZNEKFPnMYsOHz4sjRo1ktWrV8tVV10lBQUF0rBhQ5k3b570799fRH5qFHbRRRfJ2rVr5fLLLz/vOQsLCyUhISHQKdlGrVq1fI5//etfa2O6deum1fwbNouIfP3111qtc+fOWu3ee+/VahdeeKHPsal58hdffKHVBg8erNUOHjyo1cKloKBA4uPjwz0NxyPDVeOuu+7SajNmzNBqpv/b07ZtW59jU6N3JyLDlUd+f2Jq0Orf8HXatGnamF69emk1U6Pk5557Tqs9++yzWs0t2bSC/AaH2zNsyuaYMWO02pAhQ7Sa/+urcePG2hhTM1fTY1binzrafU3NXU2PeeTIEa02btw4rfbxxx9rtYKCgopMMSBkuPLcnt9g8v9bVkRk06ZNWs108QPTxYAeeeQRrXb69OkAZ+c8VvJbqZ48Z34Jnbli06ZNm6S0tFQyMzO9Y9q2bSupqamydu3ayjwUgBAgw4BzkV/A2cgw4FzkF3YW8CXUy8vLZezYsXLllVdK+/btReSny3rHxMRI3bp1fcYmJSUZL/kt8tP/+frl//0qLCwMdEoAKoAMA85FfgFnI8OAc5Ff2F3A7+TJysqSrVu3yoIFCyo1gezsbElISPDemjVrVqnzAbCGDAPORX4BZyPDgHORX9hdQJs8o0aNkr/85S+ycuVKadq0qbeenJwsp06dkvz8fJ/xeXl5kpycbDzXxIkTpaCgwHvbt29fIFMCUAFkGHAu8gs4GxkGnIv8wgkq9HEtpZSMHj1alixZIqtWrZK0tDSfr3fq1Emio6Nl+fLl0q9fPxER2bFjh+zdu1cyMjKM5/R4POLxeAKcvn35NzieP3++NqZ169ZarUePHpZq7dq102qm3d/y8nKf4x9//FEbs3LlSq1WFU3fUPXIcOhFRup756Zme6YGcVu3btVqp06dCs7E4Hjk18zUqLFDhw4+xxdddJE25tChQ1otJydHq73yyitajVwiENUtw6ZG5lYz5v+9+Z//+R9tjKlhs2m9LSoq0monTpzQahs3btRqLVu29Dles2aNNsbUiP2XV1w6w7TuV6YpNKpWdctvZfg3I7/66qu1MaaLFXz55Zda7amnntJq1anJcqAqtMmTlZUl8+bNk/fff1/i4uK8ny9MSEiQmjVrSkJCggwfPlzGjx8v9evXl/j4eBk9erRkZGRY6igOILTIMOBc5BdwNjIMOBf5hZNUaJPn1VdfFRH9nSWzZ8+WYcOGiYjI9OnTJTIyUvr16yclJSXSs2dP4w49gKpHhgHnIr+As5FhwLnIL5ykwh/XOp/Y2FiZMWOGzJgxI+BJAQgNMgw4F/kFnI0MA85FfuEkAV9dCwAAAAAAAPZRoXfywDr/hsfHjx/XxixfvlyrXX/99VrN1GS5Rg39R/fpp59qtWPHjvkc/9///Z825p///KdWMzWkA3B+tWrV0mpdu3a1NM7UHDIiIsLnmCaNqM788yAiEhcXp9XGjRvnc9ymTRttzBdffKHVZs2apdVosgwEj2kNMzVg3b59+zmPRUTee+89rWZqxF5aWqrVTE2hrWANBnyZ1mX/NXfSpEnaGP9/K4uYm5hzMaDA8E4eAAAAAAAAF2CTBwAAAAAAwAXY5AEAAAAAAHABNnkAAAAAAABcgMbLVcTUXGrNmjVabffu3VotMTFRqyUkJGi1zz//XKv5N6syNbc7ffq0VgMQmKZNm2q11NRUrRYVFaXVTI2XafII/Mzj8Wi1vn37arUrr7zyvPcz1UwXSQgmU4NKMg4ExtQ8mQuHAFUrNjZWq+Xk5PgcJycna2Py8/O12qpVq4I0K/BOHgAAAAAAABdgkwcAAAAAAMAF2OQBAAAAAABwATZ5AAAAAAAAXIDGy1XE1FixuLhYq23fvr0qpgMgCExNVH/1q19ptchIfT/d1PB83759530MmrSiOqtdu7ZWGz58uFbzb6psuvjB+++/r9VCnS/yCwBwKtPfvc2bN9dq/n8Ll5aWamP+9Kc/abXCwsJKzA6/xDt5AAAAAAAAXIBNHgAAAAAAABdgkwcAAAAAAMAF6MkTRnw2H3CfXbt2aTVTr53Dhw9rtcWLF4dkToBbmPpbHTt2TKv552vbtm3amOnTp2s1U++eUDP1OODvAwCAE5j67fj/Pbt3715tTE5OjqVzhZpb12DeyQMAAAAAAOACbPIAAAAAAAC4AJs8AAAAAAAALsAmDwAAAAAAgAvQeBkAgui7777Tag888IBWO3jwoFbbuXOnVnND8zcgWE6cOKHVRo0apdX8mzEXFxdrYwoLC4M3MQAAXM7UpNh0cZEHH3zQ5zgqKkobc/LkyeBNDBreyQMAAAAAAOACbPIAAAAAAAC4AJs8AAAAAAAALsAmDwAAAAAAgAu4vvFyZKS+j1VeXh6GmThLjRr6S+P06dNhmAmqO1OTt8o0Iw7m+UyN5A4fPqzVPvvsM63m3xhWxJw7f1bnH+zvGxAIq2uw6fVqykNZWZlW27Ztm1aLjo72Obbz+kV+AQChUJl/B5vua6qdOnXqvONMY+zCtLa6Yf+Ad/IAAAAAAAC4AJs8AAAAAAAALsAmDwAAAAAAgAvYridPsD9zzmfYA2P375vd51ed2T3DwTyf6VxVUQt0bnZi9/lVV+HKW7Dz4D/Oaa83u8/X7vOrzvjZwApeJ/Zkp795g7kGO43d529lfrbb5CkqKgrq+ez+Q7IrU3NLOykqKpKEhIRwTwMGwc6wnVnNSWFhoaVxdm5MF2xk2J7stAabmiVbbaBs50bLbkB+7as6rcEIHBm2Jzutwab7Wv271+n//rb7/K3kN0LZ7FmUl5fLgQMHJC4uToqKiqRZs2ayb98+iY+PD/fUKqywsNDR8xex33NQSklRUZGkpKQYO58j/M5kWCklqamptnntBMJur/+KsuP8ybC9sQbbi92eA/m1P9Zg+7Dj/MmwvbEG24vdnkNF8mu7d/JERkZK06ZNReTnS4jGx8fb4hsbKKfPX8Rez4H/82BvZzJ85t0rdnrtBMrpz8Fu8yfD9sUabE92eg7k195Yg+3HbvMnw/bFGmxPdnoOVvPLFi4AAAAAAIALsMkDAAAAAADgArbe5PF4PDJ58mTxeDzhnkpAnD5/EXc8B4SHG147Tn8OTp8/wsvprx+nz1/EHc8B4eGG147Tn4PT54/wcvrrx+nzF3H2c7Bd42UAAAAAAABUnK3fyQMAAAAAAABr2OQBAAAAAABwATZ5AAAAAAAAXIBNHgAAAAAAABew7SbPjBkzpEWLFhIbGytdunSRDRs2hHtKZ/XJJ5/ILbfcIikpKRIRESFLly71+bpSSh5//HFp3Lix1KxZUzIzM+Wbb74Jz2QNsrOzpXPnzhIXFyeNGjWSPn36yI4dO3zGnDx5UrKysqRBgwZSp04d6devn+Tl5YVpxnACMlx1yDCCjfxWHfKLUCDDVYcMI9jIb9Vxa35tucmzcOFCGT9+vEyePFk+++wz6dChg/Ts2VMOHToU7qkZFRcXS4cOHWTGjBnGr0+dOlVefPFFmTlzpqxfv15q164tPXv2lJMnT1bxTM1Wr14tWVlZsm7dOlm2bJmUlpbKddddJ8XFxd4x48aNkw8//FAWLVokq1evlgMHDsitt94axlnDzshw1SLDCCbyW7XIL4KNDFctMoxgIr9Vy7X5VTaUnp6usrKyvMdlZWUqJSVFZWdnh3FW1oiIWrJkife4vLxcJScnq+eee85by8/PVx6PR82fPz8MMzy/Q4cOKRFRq1evVkr9NN/o6Gi1aNEi75ivvvpKiYhau3ZtuKYJGyPD4UWGURnkN7zILyqLDIcXGUZlkN/wckt+bfdOnlOnTsmmTZskMzPTW4uMjJTMzExZu3ZtGGcWmF27dklubq7P80lISJAuXbrY9vkUFBSIiEj9+vVFRGTTpk1SWlrq8xzatm0rqamptn0OCB8yHH5kGIEiv+FHflEZZDj8yDACRX7Dzy35td0mz5EjR6SsrEySkpJ86klJSZKbmxumWQXuzJyd8nzKy8tl7NixcuWVV0r79u1F5KfnEBMTI3Xr1vUZa9fngPAiw+FFhlEZ5De8yC8qiwyHFxlGZZDf8HJTfmuEewKwl6ysLNm6dausWbMm3FMBEAAyDDgX+QWcjQwDzuWm/NrunTyJiYkSFRWldazOy8uT5OTkMM0qcGfm7ITnM2rUKPnLX/4iK1eulKZNm3rrycnJcurUKcnPz/cZb8fngPAjw+FDhlFZ5Dd8yC+CgQyHDxlGZZHf8HFbfm23yRMTEyOdOnWS5cuXe2vl5eWyfPlyycjICOPMApOWlibJyck+z6ewsFDWr19vm+ejlJJRo0bJkiVLZMWKFZKWlubz9U6dOkl0dLTPc9ixY4fs3bvXNs8B9kGGqx4ZRrCQ36pHfhFMZLjqkWEEC/mteq7Nb1jbPp/FggULlMfjUXPmzFHbtm1TI0aMUHXr1lW5ubnhnppRUVGR+vzzz9Xnn3+uRERNmzZNff7552rPnj1KKaWeeeYZVbduXfX++++rLVu2qN69e6u0tDR14sSJMM/8Jw888IBKSEhQq1atUgcPHvTejh8/7h1z//33q9TUVLVixQq1ceNGlZGRoTIyMsI4a9gZGa5aZBjBRH6rFvlFsJHhqkWGEUzkt2q5Nb+23ORRSqmXXnpJpaamqpiYGJWenq7WrVsX7imd1cqVK5WIaLehQ4cqpX66fNykSZNUUlKS8ng86tprr1U7duwI76R/wTR3EVGzZ8/2jjlx4oQaOXKkqlevnqpVq5bq27evOnjwYPgmDdsjw1WHDCPYyG/VIb8IBTJcdcgwgo38Vh235jdCKaWC854gAAAAAAAAhIvtevIAAAAAAACg4tjkAQAAAAAAcAE2eQAAAAAAAFyATR4AAAAAAAAXYJMHAAAAAADABdjkAQAAAAAAcAE2eQAAAAAAAFyATR4AAAAAAAAXYJMHAAAAAADABdjkAQAAAAAAcAE2eQAAAAAAAFyATR4AAAAAAAAX+H9qfLxM9L2F+wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1500x600 with 15 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_test_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "original_test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=original_transform)\n",
    "\n",
    "paired_test_dataset = PairedDataset(original_test_dataset)\n",
    "test_loader = DataLoader(paired_test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ... (after training) ...\n",
    "with torch.no_grad():\n",
    "    images, noisy_images, _ = next(iter(test_loader))\n",
    "    output = model(noisy_images.to(device))\n",
    "    # Plot original and reconstructed images side-by-side\n",
    "    # Select some images to visualize (adjust the number if needed)\n",
    "    images_to_show = 5 \n",
    "\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=images_to_show, figsize=(15, 6))\n",
    "\n",
    "    # Plot original images\n",
    "    for i in range(images_to_show):\n",
    "        axes[0, i].imshow(images[i].cpu().squeeze().numpy(), cmap='gray')\n",
    "        axes[0, i].set_title('Original')\n",
    "        \n",
    "    # Plot reconstructed images\n",
    "    for i in range(images_to_show):\n",
    "        axes[1, i].imshow(noisy_images[i].cpu().squeeze().numpy(), cmap='gray')\n",
    "        axes[1, i].set_title('Noisy')\n",
    "        \n",
    "    # Plot reconstructed images\n",
    "    for i in range(images_to_show):\n",
    "        axes[2, i].imshow(output[i].cpu().squeeze().numpy(), cmap='gray')\n",
    "        axes[2, i].set_title('Reconstructed')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1dd7ff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = images[0].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b236472a-7c96-4cd6-a732-2c4b312290e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc3bfd89-0b5c-46b0-9f8c-c2fa70d4289b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function squeeze:\n",
      "\n",
      "squeeze(...) method of torch.Tensor instance\n",
      "    squeeze(dim=None) -> Tensor\n",
      "    \n",
      "    See :func:`torch.squeeze`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(image.squeeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70e5c682-6558-4ff2-b206-0e79938db6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function squeeze in module torch:\n",
      "\n",
      "squeeze(...)\n",
      "    squeeze(input, dim=None) -> Tensor\n",
      "    \n",
      "    Returns a tensor with all specified dimensions of :attr:`input` of size `1` removed.\n",
      "    \n",
      "    For example, if `input` is of shape:\n",
      "    :math:`(A \\times 1 \\times B \\times C \\times 1 \\times D)` then the `input.squeeze()`\n",
      "    will be of shape: :math:`(A \\times B \\times C \\times D)`.\n",
      "    \n",
      "    When :attr:`dim` is given, a squeeze operation is done only in the given\n",
      "    dimension(s). If `input` is of shape: :math:`(A \\times 1 \\times B)`,\n",
      "    ``squeeze(input, 0)`` leaves the tensor unchanged, but ``squeeze(input, 1)``\n",
      "    will squeeze the tensor to the shape :math:`(A \\times B)`.\n",
      "    \n",
      "    .. note:: The returned tensor shares the storage with the input tensor,\n",
      "              so changing the contents of one will change the contents of the other.\n",
      "    \n",
      "    .. warning:: If the tensor has a batch dimension of size 1, then `squeeze(input)`\n",
      "              will also remove the batch dimension, which can lead to unexpected\n",
      "              errors. Consider specifying only the dims you wish to be squeezed.\n",
      "    \n",
      "    Args:\n",
      "        input (Tensor): the input tensor.\n",
      "        dim (int or tuple of ints, optional): if given, the input will be squeezed\n",
      "               only in the specified dimensions.\n",
      "    \n",
      "            .. versionchanged:: 2.0\n",
      "               :attr:`dim` now accepts tuples of dimensions.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> x = torch.zeros(2, 1, 2, 1, 2)\n",
      "        >>> x.size()\n",
      "        torch.Size([2, 1, 2, 1, 2])\n",
      "        >>> y = torch.squeeze(x)\n",
      "        >>> y.size()\n",
      "        torch.Size([2, 2, 2])\n",
      "        >>> y = torch.squeeze(x, 0)\n",
      "        >>> y.size()\n",
      "        torch.Size([2, 1, 2, 1, 2])\n",
      "        >>> y = torch.squeeze(x, 1)\n",
      "        >>> y.size()\n",
      "        torch.Size([2, 2, 1, 2])\n",
      "        >>> y = torch.squeeze(x, (1, 2, 3))\n",
      "        torch.Size([2, 2, 2])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.squeeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3c7bbdc-c00c-4d75-9935-c11081cfecee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = image.squeeze()\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c83a0f64-ec81-4114-b89b-d4f0cb120e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.4510,  0.4902,  1.0000,\n",
       "          0.5451, -0.4039, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -0.8667, -0.0510,  0.9373,  0.9765,  0.9843,\n",
       "          0.9765,  0.9373, -0.7098, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -0.2941,  0.9765,  0.9765,  0.9765,  0.9843,\n",
       "          0.9765,  0.9765, -0.6941, -1.0000, -1.0000, -1.0000, -1.0000, -0.9608,\n",
       "         -0.2627, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -0.3098,  0.8824,  0.9765,  0.9765,  0.9765,  0.9843,\n",
       "         -0.0588, -0.6941, -0.9529, -1.0000, -1.0000, -1.0000, -1.0000, -0.8902,\n",
       "          0.9765, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000,  0.4588,  0.9765,  0.9765,  0.9765,  0.9765, -0.5843,\n",
       "         -0.9765, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8902,\n",
       "          0.9765, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -0.3882,  0.8431,  0.9765,  0.9765,  0.9529,  0.0039, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8902,\n",
       "          0.9765, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -0.5608,  0.8510,  0.9765,  0.9765,  0.9765,  0.7020, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8902,\n",
       "          0.9765, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -0.2549,  0.9765,  0.9765,  0.9765,  0.8431, -0.6941, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8902,\n",
       "          0.9765, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.5137,\n",
       "          0.8510,  0.9765,  0.9765,  0.9608,  0.1216, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9529,\n",
       "          0.4353, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.7725,\n",
       "          0.9765,  0.9765,  0.9765,  0.6627, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -0.1059, -0.2235, -1.0000, -1.0000, -1.0000, -0.9373,\n",
       "          0.5373, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.6000,  0.8824,\n",
       "          0.9843,  0.9843,  0.9843,  0.1686, -1.0000, -1.0000, -1.0000, -0.0510,\n",
       "          0.3804,  0.9843,  0.9843,  0.9843,  0.9843,  0.2627, -0.6549, -0.8902,\n",
       "          0.9843, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.6000,  0.8745,  0.9765,\n",
       "          0.9765,  0.9765,  0.1294, -0.9686, -0.4667,  0.4431,  0.8824,  0.9843,\n",
       "          0.9765,  0.9765,  0.9765,  0.9765,  0.9765,  0.9765,  0.7176, -0.8902,\n",
       "          0.9765, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.0510,  0.9765,  0.9765,\n",
       "          0.9765,  0.9765,  0.2706,  0.7725,  0.9059,  0.9765,  0.9765,  0.9843,\n",
       "          0.9765,  0.9765,  0.9765,  0.9765,  0.9765,  0.9765,  0.9529, -0.1451,\n",
       "          0.9765, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.2706,  0.9765,  0.9765,\n",
       "          0.9765,  0.9765,  0.9765,  0.9765,  0.9765,  0.9765,  0.9765,  0.9843,\n",
       "          0.9765,  0.9765,  0.4431,  0.5137,  0.9765,  0.9765,  0.9765, -0.0667,\n",
       "          0.9765, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.1529,  0.9765,  0.9765,\n",
       "          0.9765,  0.9765,  0.9765,  0.9765,  0.9765,  0.6706,  0.4510,  0.4588,\n",
       "         -0.5373, -0.5843, -0.9373, -0.1922,  0.9765,  0.9765,  0.8118, -0.7176,\n",
       "          0.9765, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.0510,  0.9765,  0.9765,\n",
       "          0.9765,  0.9765,  0.9765,  0.9765,  0.9765,  0.6784, -0.0824, -0.5765,\n",
       "         -0.5765, -0.1922,  0.4588,  0.8667,  0.9765,  0.9765,  0.5451, -0.8902,\n",
       "          0.9765, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.7020,  0.7412,  0.9765,\n",
       "          0.9765,  0.9765,  0.9765,  0.9765,  0.9765,  0.9765,  0.9765,  0.9843,\n",
       "          0.9765,  0.9765,  0.9765,  0.9765,  0.9765,  0.7569, -0.3882, -0.8902,\n",
       "          0.9765, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.6941,  0.8510,\n",
       "          0.9765,  0.9765,  0.9765,  0.9765,  0.9765,  0.9765,  0.9765,  0.9843,\n",
       "          0.9765,  0.9765,  0.9765,  0.9765,  0.8196, -0.4431, -1.0000, -0.8902,\n",
       "          0.8667, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.2549,\n",
       "          0.1529,  0.8667,  0.9451,  0.9765,  0.9765,  0.9765,  0.9765,  0.9843,\n",
       "          0.9765,  0.9765,  0.8902,  0.5922, -0.7804, -1.0000, -1.0000, -0.9529,\n",
       "         -0.6078, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -0.3020, -0.0667, -0.0667, -0.0118,  0.9765,  0.4902,\n",
       "         -0.0667, -0.0667, -0.8510, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -1.0000, -1.0000, -1.0000, -1.0000]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b460f75b-ee6a-4232-819f-6894bc77b898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function imshow in module matplotlib.pyplot:\n",
      "\n",
      "imshow(X, cmap=None, norm=None, *, aspect=None, interpolation=None, alpha=None, vmin=None, vmax=None, origin=None, extent=None, interpolation_stage=None, filternorm=True, filterrad=4.0, resample=None, url=None, data=None, **kwargs)\n",
      "    Display data as an image, i.e., on a 2D regular raster.\n",
      "    \n",
      "    The input may either be actual RGB(A) data, or 2D scalar data, which\n",
      "    will be rendered as a pseudocolor image. For displaying a grayscale\n",
      "    image set up the colormapping using the parameters\n",
      "    ``cmap='gray', vmin=0, vmax=255``.\n",
      "    \n",
      "    The number of pixels used to render an image is set by the Axes size\n",
      "    and the *dpi* of the figure. This can lead to aliasing artifacts when\n",
      "    the image is resampled because the displayed image size will usually\n",
      "    not match the size of *X* (see\n",
      "    :doc:`/gallery/images_contours_and_fields/image_antialiasing`).\n",
      "    The resampling can be controlled via the *interpolation* parameter\n",
      "    and/or :rc:`image.interpolation`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    X : array-like or PIL image\n",
      "        The image data. Supported array shapes are:\n",
      "    \n",
      "        - (M, N): an image with scalar data. The values are mapped to\n",
      "          colors using normalization and a colormap. See parameters *norm*,\n",
      "          *cmap*, *vmin*, *vmax*.\n",
      "        - (M, N, 3): an image with RGB values (0-1 float or 0-255 int).\n",
      "        - (M, N, 4): an image with RGBA values (0-1 float or 0-255 int),\n",
      "          i.e. including transparency.\n",
      "    \n",
      "        The first two dimensions (M, N) define the rows and columns of\n",
      "        the image.\n",
      "    \n",
      "        Out-of-range RGB(A) values are clipped.\n",
      "    \n",
      "    cmap : str or `~matplotlib.colors.Colormap`, default: :rc:`image.cmap`\n",
      "        The Colormap instance or registered colormap name used to map scalar data\n",
      "        to colors.\n",
      "    \n",
      "        This parameter is ignored if *X* is RGB(A).\n",
      "    \n",
      "    norm : str or `~matplotlib.colors.Normalize`, optional\n",
      "        The normalization method used to scale scalar data to the [0, 1] range\n",
      "        before mapping to colors using *cmap*. By default, a linear scaling is\n",
      "        used, mapping the lowest value to 0 and the highest to 1.\n",
      "    \n",
      "        If given, this can be one of the following:\n",
      "    \n",
      "        - An instance of `.Normalize` or one of its subclasses\n",
      "          (see :doc:`/tutorials/colors/colormapnorms`).\n",
      "        - A scale name, i.e. one of \"linear\", \"log\", \"symlog\", \"logit\", etc.  For a\n",
      "          list of available scales, call `matplotlib.scale.get_scale_names()`.\n",
      "          In that case, a suitable `.Normalize` subclass is dynamically generated\n",
      "          and instantiated.\n",
      "    \n",
      "        This parameter is ignored if *X* is RGB(A).\n",
      "    \n",
      "    vmin, vmax : float, optional\n",
      "        When using scalar data and no explicit *norm*, *vmin* and *vmax* define\n",
      "        the data range that the colormap covers. By default, the colormap covers\n",
      "        the complete value range of the supplied data. It is an error to use\n",
      "        *vmin*/*vmax* when a *norm* instance is given (but using a `str` *norm*\n",
      "        name together with *vmin*/*vmax* is acceptable).\n",
      "    \n",
      "        This parameter is ignored if *X* is RGB(A).\n",
      "    \n",
      "    aspect : {'equal', 'auto'} or float, default: :rc:`image.aspect`\n",
      "        The aspect ratio of the Axes.  This parameter is particularly\n",
      "        relevant for images since it determines whether data pixels are\n",
      "        square.\n",
      "    \n",
      "        This parameter is a shortcut for explicitly calling\n",
      "        `.Axes.set_aspect`. See there for further details.\n",
      "    \n",
      "        - 'equal': Ensures an aspect ratio of 1. Pixels will be square\n",
      "          (unless pixel sizes are explicitly made non-square in data\n",
      "          coordinates using *extent*).\n",
      "        - 'auto': The Axes is kept fixed and the aspect is adjusted so\n",
      "          that the data fit in the Axes. In general, this will result in\n",
      "          non-square pixels.\n",
      "    \n",
      "    interpolation : str, default: :rc:`image.interpolation`\n",
      "        The interpolation method used.\n",
      "    \n",
      "        Supported values are 'none', 'antialiased', 'nearest', 'bilinear',\n",
      "        'bicubic', 'spline16', 'spline36', 'hanning', 'hamming', 'hermite',\n",
      "        'kaiser', 'quadric', 'catrom', 'gaussian', 'bessel', 'mitchell',\n",
      "        'sinc', 'lanczos', 'blackman'.\n",
      "    \n",
      "        If *interpolation* is 'none', then no interpolation is performed\n",
      "        on the Agg, ps, pdf and svg backends. Other backends will fall back\n",
      "        to 'nearest'. Note that most SVG renderers perform interpolation at\n",
      "        rendering and that the default interpolation method they implement\n",
      "        may differ.\n",
      "    \n",
      "        If *interpolation* is the default 'antialiased', then 'nearest'\n",
      "        interpolation is used if the image is upsampled by more than a\n",
      "        factor of three (i.e. the number of display pixels is at least\n",
      "        three times the size of the data array).  If the upsampling rate is\n",
      "        smaller than 3, or the image is downsampled, then 'hanning'\n",
      "        interpolation is used to act as an anti-aliasing filter, unless the\n",
      "        image happens to be upsampled by exactly a factor of two or one.\n",
      "    \n",
      "        See\n",
      "        :doc:`/gallery/images_contours_and_fields/interpolation_methods`\n",
      "        for an overview of the supported interpolation methods, and\n",
      "        :doc:`/gallery/images_contours_and_fields/image_antialiasing` for\n",
      "        a discussion of image antialiasing.\n",
      "    \n",
      "        Some interpolation methods require an additional radius parameter,\n",
      "        which can be set by *filterrad*. Additionally, the antigrain image\n",
      "        resize filter is controlled by the parameter *filternorm*.\n",
      "    \n",
      "    interpolation_stage : {'data', 'rgba'}, default: 'data'\n",
      "        If 'data', interpolation\n",
      "        is carried out on the data provided by the user.  If 'rgba', the\n",
      "        interpolation is carried out after the colormapping has been\n",
      "        applied (visual interpolation).\n",
      "    \n",
      "    alpha : float or array-like, optional\n",
      "        The alpha blending value, between 0 (transparent) and 1 (opaque).\n",
      "        If *alpha* is an array, the alpha blending values are applied pixel\n",
      "        by pixel, and *alpha* must have the same shape as *X*.\n",
      "    \n",
      "    origin : {'upper', 'lower'}, default: :rc:`image.origin`\n",
      "        Place the [0, 0] index of the array in the upper left or lower\n",
      "        left corner of the Axes. The convention (the default) 'upper' is\n",
      "        typically used for matrices and images.\n",
      "    \n",
      "        Note that the vertical axis points upward for 'lower'\n",
      "        but downward for 'upper'.\n",
      "    \n",
      "        See the :doc:`/tutorials/intermediate/imshow_extent` tutorial for\n",
      "        examples and a more detailed description.\n",
      "    \n",
      "    extent : floats (left, right, bottom, top), optional\n",
      "        The bounding box in data coordinates that the image will fill.\n",
      "        These values may be unitful and match the units of the Axes.\n",
      "        The image is stretched individually along x and y to fill the box.\n",
      "    \n",
      "        The default extent is determined by the following conditions.\n",
      "        Pixels have unit size in data coordinates. Their centers are on\n",
      "        integer coordinates, and their center coordinates range from 0 to\n",
      "        columns-1 horizontally and from 0 to rows-1 vertically.\n",
      "    \n",
      "        Note that the direction of the vertical axis and thus the default\n",
      "        values for top and bottom depend on *origin*:\n",
      "    \n",
      "        - For ``origin == 'upper'`` the default is\n",
      "          ``(-0.5, numcols-0.5, numrows-0.5, -0.5)``.\n",
      "        - For ``origin == 'lower'`` the default is\n",
      "          ``(-0.5, numcols-0.5, -0.5, numrows-0.5)``.\n",
      "    \n",
      "        See the :doc:`/tutorials/intermediate/imshow_extent` tutorial for\n",
      "        examples and a more detailed description.\n",
      "    \n",
      "    filternorm : bool, default: True\n",
      "        A parameter for the antigrain image resize filter (see the\n",
      "        antigrain documentation).  If *filternorm* is set, the filter\n",
      "        normalizes integer values and corrects the rounding errors. It\n",
      "        doesn't do anything with the source floating point values, it\n",
      "        corrects only integers according to the rule of 1.0 which means\n",
      "        that any sum of pixel weights must be equal to 1.0.  So, the\n",
      "        filter function must produce a graph of the proper shape.\n",
      "    \n",
      "    filterrad : float > 0, default: 4.0\n",
      "        The filter radius for filters that have a radius parameter, i.e.\n",
      "        when interpolation is one of: 'sinc', 'lanczos' or 'blackman'.\n",
      "    \n",
      "    resample : bool, default: :rc:`image.resample`\n",
      "        When *True*, use a full resampling method.  When *False*, only\n",
      "        resample when the output image is larger than the input image.\n",
      "    \n",
      "    url : str, optional\n",
      "        Set the url of the created `.AxesImage`. See `.Artist.set_url`.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    `~matplotlib.image.AxesImage`\n",
      "    \n",
      "    Other Parameters\n",
      "    ----------------\n",
      "    data : indexable object, optional\n",
      "        If given, all parameters also accept a string ``s``, which is\n",
      "        interpreted as ``data[s]`` (unless this raises an exception).\n",
      "    \n",
      "    **kwargs : `~matplotlib.artist.Artist` properties\n",
      "        These parameters are passed on to the constructor of the\n",
      "        `.AxesImage` artist.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    matshow : Plot a matrix or an array as an image.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Unless *extent* is used, pixel centers will be located at integer\n",
      "    coordinates. In other words: the origin will coincide with the center\n",
      "    of pixel (0, 0).\n",
      "    \n",
      "    There are two common representations for RGB images with an alpha\n",
      "    channel:\n",
      "    \n",
      "    -   Straight (unassociated) alpha: R, G, and B channels represent the\n",
      "        color of the pixel, disregarding its opacity.\n",
      "    -   Premultiplied (associated) alpha: R, G, and B channels represent\n",
      "        the color of the pixel, adjusted for its opacity by multiplication.\n",
      "    \n",
      "    `~matplotlib.pyplot.imshow` expects RGB images adopting the straight\n",
      "    (unassociated) alpha representation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(plt.imshow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b3a9b89-dab0-4bec-bb3d-c865309d1a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7feea34ce4c0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(s.numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af87d2f9-cd03-4f0a-9cbf-05c4bf4a864c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
