{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ef4f340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import gzip\n",
    "%matplotlib inline\n",
    "from keras.layers import Input,Conv2D,MaxPooling2D,UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "147bf4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(filename, num_images):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(28 * 28 * num_images)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        data = data.reshape(num_images, 28,28)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "261789f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = extract_data('train-images-idx3-ubyte.gz', 60000)\n",
    "test_data = extract_data('t10k-images-idx3-ubyte.gz', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4345cf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(filename, num_images):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * num_images)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2728bf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = extract_labels('train-labels-idx1-ubyte.gz',60000)\n",
    "test_labels = extract_labels('t10k-labels-idx1-ubyte.gz',10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb122b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (images) shape: (60000, 28, 28)\n",
      "Test set (images) shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Shapes of training set\n",
    "print(\"Training set (images) shape: {shape}\".format(shape=train_data.shape))\n",
    "\n",
    "# Shapes of test set\n",
    "print(\"Test set (images) shape: {shape}\".format(shape=test_data.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb2b694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of target classes\n",
    "label_dict = {\n",
    " 0: '0',\n",
    " 1: '1',\n",
    " 2: '2',\n",
    " 3: '3',\n",
    " 4: '4',\n",
    " 5: '5',\n",
    " 6: '6',\n",
    " 7: '7',\n",
    " 8: '8',\n",
    " 9: '9',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d08c0173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '(Label: 7)')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[5,5])\n",
    "\n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "curr_img = np.reshape(train_data[0], (28,28))\n",
    "curr_lbl = train_labels[0]\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "curr_img = np.reshape(test_data[0], (28,28))\n",
    "curr_lbl = test_labels[0]\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2cc5eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.reshape(-1, 28,28, 1)\n",
    "test_data = test_data.reshape(-1, 28,28, 1)\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "322b0597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float32'), dtype('float32'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dtype, test_data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "819184a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255.0, 255.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(train_data), np.max(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "809cbc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data / np.max(train_data)\n",
    "test_data = test_data / np.max(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b60c97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(train_data), np.max(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3891b597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X,valid_X,train_ground,valid_ground = train_test_split(train_data,\n",
    "                                                             train_data, \n",
    "                                                             test_size=0.2, \n",
    "                                                             random_state=13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f90a7863",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 50\n",
    "inChannel = 1\n",
    "x, y = 28, 28\n",
    "input_img = Input(shape = (x, y, inChannel))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e40267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder(input_img):\n",
    "    #encoder\n",
    "    #input = 28 x 28 x 1 (wide and thin)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img) #28 x 28 x 32\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) #14 x 14 x 32\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) #14 x 14 x 64\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) #7 x 7 x 64\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)\n",
    "\n",
    "    #decoder\n",
    "    conv4 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3) #7 x 7 x 128\n",
    "    up1 = UpSampling2D((2,2))(conv4) # 14 x 14 x 128\n",
    "    conv5 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1) # 14 x 14 x 64\n",
    "    up2 = UpSampling2D((2,2))(conv5) # 28 x 28 x 64\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1\n",
    "    return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3c156de",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(input_img, autoencoder(input_img))\n",
    "autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4c2e36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 14, 14, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 7, 7, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 7, 7, 128)         147584    \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2  (None, 14, 14, 128)       0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 14, 14, 64)        73792     \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSamplin  (None, 28, 28, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 28, 28, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 314625 (1.20 MB)\n",
      "Trainable params: 314625 (1.20 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22de3e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "375/375 [==============================] - 67s 177ms/step - loss: 0.1130 - val_loss: 0.1123\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 66s 177ms/step - loss: 0.1119 - val_loss: 0.1123\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 67s 179ms/step - loss: 0.1119 - val_loss: 0.1123\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 67s 178ms/step - loss: 0.1119 - val_loss: 0.1123\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 67s 179ms/step - loss: 0.1119 - val_loss: 0.1123\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 69s 183ms/step - loss: 0.1119 - val_loss: 0.1123\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 69s 183ms/step - loss: 0.1119 - val_loss: 0.1123\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 69s 184ms/step - loss: 0.1119 - val_loss: 0.1123\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 68s 181ms/step - loss: 0.1119 - val_loss: 0.1123\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 69s 183ms/step - loss: 0.1119 - val_loss: 0.1123\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 69s 183ms/step - loss: 0.1119 - val_loss: 0.1123\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 68s 182ms/step - loss: 0.1119 - val_loss: 0.1123\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 69s 184ms/step - loss: 0.1119 - val_loss: 0.1123\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 69s 183ms/step - loss: 0.1119 - val_loss: 0.1123\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 69s 183ms/step - loss: 0.1119 - val_loss: 0.1123\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 68s 182ms/step - loss: 0.1119 - val_loss: 0.1123\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 69s 184ms/step - loss: 0.1119 - val_loss: 0.1123\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 69s 183ms/step - loss: 0.1119 - val_loss: 0.1123\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 69s 184ms/step - loss: 0.1119 - val_loss: 0.1123\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 68s 182ms/step - loss: 0.1119 - val_loss: 0.1123\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 68s 183ms/step - loss: 0.1119 - val_loss: 0.1123\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 69s 183ms/step - loss: 0.1119 - val_loss: 0.1123\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 68s 181ms/step - loss: 0.1119 - val_loss: 0.1123\n",
      "Epoch 24/50\n",
      " 74/375 [====>.........................] - ETA: 52s - loss: 0.1122"
     ]
    }
   ],
   "source": [
    "autoencoder_train = autoencoder.fit(train_X, train_ground, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_ground))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd761902",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
